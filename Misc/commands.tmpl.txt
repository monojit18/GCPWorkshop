====================================================================================================
New Approach
====================================================================================================
# Organizations
=====================
gcloud organizations list

====================================================================================================

# Folders
=====================
gcloud resource-manager folders create --display-name=infrastructure --organization=
gcloud resource-manager folders create --display-name=services --organization=
gcloud resource-manager folders list --organization=

====================================================================================================
BASEFOLDERPATH="/Users/monojitd/Workloads/Development/Projects/GithubProjects/Workshops/GCPWorkshop"
PROJECT_HUB="cloud-native-hub"
GSA_HUB="infrastructure-hub-sa@${PROJECT_HUB}.iam.gserviceaccount.com"

PROJECT_SPOKE="cloud-native-spoke"
GSA_SPOKE="infrastructure-spoke-sa@${PROJECT_SPOKE}.iam.gserviceaccount.com"

PROJECT_APPS="cloud-native-services-apps"
GSA_APPS="services-apps-sa@${PROJECT_APPS}.iam.gserviceaccount.com"

PROJECT_DBS="cloud-native-services-dbs"
GSA_DBS="services-dbs-sa@${PROJECT_DBS}.iam.gserviceaccount.com"

REGION="asia-southeast1"
ZONE="asia-southeast1-b"
====================================================================================================

# Projects
=====================
gcloud config get project

gcloud projects create $PROJECT_HUB --folder=
gcloud config set project $PROJECT_HUB
gcloud beta billing projects link $PROJECT_HUB --billing-account=
gcloud services enable compute.googleapis.com
gcloud config set compute/region $REGION
gcloud config set compute/zone $ZONE

gcloud projects create $PROJECT_SPOKE --folder=
gcloud config set project $PROJECT_SPOKE
gcloud beta billing projects link $PROJECT_SPOKE --billing-account=
gcloud services enable compute.googleapis.com
gcloud config set compute/region $REGION
gcloud config set compute/zone $ZONE

gcloud projects create $PROJECT_APPS --folder=
gcloud config set project $PROJECT_APPS
gcloud beta billing projects link $PROJECT_APPS --billing-account=
gcloud services enable compute.googleapis.com
gcloud config set compute/region $REGION
gcloud config set compute/zone $ZONE

gcloud projects create $PROJECT_DBS --folder=
gcloud config set project $PROJECT_DBS
gcloud beta billing projects link $PROJECT_DBS --billing-account=
gcloud services enable compute.googleapis.com
gcloud config set compute/region $REGION
gcloud config set compute/zone $ZONE

# Service Accounts
=========================

gcloud config set project $PROJECT_HUB
gcloud iam service-accounts create infrastructure-hub-sa --display-name "SA for All Hub Infratsructure"
gcloud iam service-accounts list
gcloud iam service-accounts keys \
create "${BASEFOLDERPATH}/Misc/infrastructure-hub-sa.json" \
--iam-account=$GSA_HUB

gcloud projects add-iam-policy-binding $PROJECT_HUB --role="roles/owner" \
--member="serviceAccount:${GSA_HUB}"

=========================
gcloud config set project $PROJECT_SPOKE
gcloud iam service-accounts create infrastructure-spoke-sa --display-name "SA for All Spoke Infratsructure"
gcloud iam service-accounts list

gcloud iam service-accounts keys \
create "${BASEFOLDERPATH}/Misc/infrastructure-spoke-sa.json" \
--iam-account=$GSA_SPOKE

gcloud projects add-iam-policy-binding $PROJECT_SPOKE --role="roles/owner" \
--member="serviceAccount:${GSA_SPOKE}"

gcloud projects add-iam-policy-binding $PROJECT_HUB --role="roles/viewer" \
--member="serviceAccount:${GSA_SPOKE}"

=========================
gcloud config set project $PROJECT_APPS
gcloud iam service-accounts create services-apps-sa --display-name "SA for All App Services"
gcloud iam service-accounts list

gcloud iam service-accounts keys \
create "${BASEFOLDERPATH}/Misc/services-apps-sa.json" \
--iam-account=$GSA_APPS

gcloud projects add-iam-policy-binding $PROJECT_APPS --role="roles/owner" \
--member="serviceAccount:${GSA_APPS}"

=========================
gcloud config set project $PROJECT_DBS
gcloud iam service-accounts create services-dbs-sa --display-name "SA for All App Services"
gcloud iam service-accounts list

gcloud iam service-accounts keys \
create "${BASEFOLDERPATH}/Misc/services-dbs-sa.json" \
--iam-account=$GSA_DBS

gcloud projects add-iam-policy-binding $PROJECT_DBS --role="roles/owner" \
--member="serviceAccount:${GSA_DBS}"

====================================================================================================

# GKE Private Cluster
====================================================================================================
## Hub Resources
=========================
PROJECT="$PROJECT_HUB"
GSA="$GSA_HUB"
HUB_VPC_NAME="hub-vpc"
HUB_SUBNET_NAME="jump-server-subnet"

gcloud auth activate-service-account $GSA \
--key-file="${BASEFOLDERPATH}/Misc/infrastructure-hub-sa.json"
gcloud config set project $PROJECT

gcloud compute networks create $HUB_VPC_NAME --project=$PROJECT --subnet-mode=custom --mtu=1460 \
--bgp-routing-mode=regional
# gcloud compute networks delete $HUB_VPC_NAME

gcloud compute firewall-rules create allow-ssh-rule --network $HUB_VPC_NAME --allow tcp:22 --source-ranges=0.0.0.0/0
# gcloud compute firewall-rules delete allow-ssh-rule

gcloud compute networks subnets create $HUB_SUBNET_NAME --network=$HUB_VPC_NAME --range=11.0.0.0/24
# gcloud compute networks subnets delete $HUB_SUBNET_NAME

### Jumper VM
===============
gcloud compute instances create jumper-server --image-family=debian-10 --image-project=debian-cloud \
--network=$HUB_VPC_NAME --subnet=$HUB_SUBNET_NAME --zone=$ZONE --project=$PROJECT_HUB
# gcloud compute instances delete jumper-server --zone=$ZONE --project=$PROJECT_HUB

gcloud compute instances describe jumper-server --format="get(networkInterfaces[0].networkIP)" \
--project=$PROJECT_HUB
gcloud compute instances describe jumper-server --format="get(networkInterfaces[0].accessConfigs[0].natIP)" \
--project=$PROJECT_HUB

gcloud compute ssh --zone $ZONE jumper-server --project=$PROJECT_HUB

### Hub-n-Spoke Peering
==============================
SPOKE_VPC_NAME="$SPOKE_VPC_NAME"

gcloud auth activate-service-account $GSA_HUB \
--key-file="${BASEFOLDERPATH}/Misc/infrastructure-hub-sa.json"
gcloud config set project $PROJECT_HUB

gcloud compute networks peerings create hub-spoke-peer --network=$HUB_VPC_NAME --peer-network=$SPOKE_VPC_NAME \
--peer-project=$PROJECT_SPOKE --import-subnet-routes-with-public-ip
# gcloud compute networks peerings delete hub-spoke-peer --network=$HUB_VPC_NAME

gcloud auth activate-service-account $GSA_SPOKE \
--key-file="${BASEFOLDERPATH}/Misc/infrastructure-spoke-sa.json"
gcloud config set project $PROJECT_SPOKE

gcloud compute networks peerings create spoke-hub-peer --network=$SPOKE_VPC_NAME \
--peer-network=$HUB_VPC_NAME --peer-project=$PROJECT_HUB --import-subnet-routes-with-public-ip
# gcloud compute networks peerings delete hub-spoke-peer --network=$HUB_VPC_NAME

## Spoke Resources
=========================
PROJECT="$PROJECT_SPOKE"
GSA="$GSA_SPOKE"
SPOKE_VPC_NAME="spoke-vpc"
CLUSTER_SUBNET_NAME="gke-cluster-subnet"
PROXY_SUBNET_NAME="gke-proxy-only-subnet"
PSC_SUBNET_NAME="gke-psc-subnet"
JUMP_SERVER_SUBNET_NAME="jumper-server-spoke-subnet"

gcloud auth activate-service-account $GSA \
--key-file="${BASEFOLDERPATH}/Misc/infrastructure-spoke-sa.json"
gcloud config set project $PROJECT

gcloud compute networks create $SPOKE_VPC_NAME --project=$PROJECT --subnet-mode=custom --mtu=1460 \
--bgp-routing-mode=regional
# gcloud compute networks delete $SPOKE_VPC_NAME

gcloud compute firewall-rules create allow-ssh-spoke-rule --network $SPOKE_VPC_NAME --allow tcp:22 --source-ranges=0.0.0.0/0
# gcloud compute firewall-rules delete allow-ssh-spoke-rule

gcloud compute networks subnets create $CLUSTER_SUBNET_NAME --network=$SPOKE_VPC_NAME --range=12.0.0.0/22
# gcloud compute networks subnets delete $CLUSTER_SUBNET_NAME

gcloud compute networks subnets create $PROXY_SUBNET_NAME --purpose=REGIONAL_MANAGED_PROXY --role=ACTIVE \
--network=$SPOKE_VPC_NAME --range=12.0.4.0/24
# gcloud compute networks subnets delete $PROXY_SUBNET_NAME

gcloud compute networks subnets create $PSC_SUBNET_NAME --purpose=PRIVATE_SERVICE_CONNECT --role=ACTIVE \
--network=$SPOKE_VPC_NAME --range=12.0.5.0/24
# gcloud compute networks subnets delete $PSC_SUBNET_NAME

gcloud compute networks subnets create $JUMP_SERVER_SUBNET_NAME --network=$SPOKE_VPC_NAME --range=12.0.7.0/24
# gcloud compute networks subnets delete $JUMP_SERVER_SUBNET_NAME

gcloud compute networks subnets update $CLUSTER_SUBNET_NAME \
--add-secondary-ranges=pods-range=12.1.0.0/16,services-range=12.2.0.0/16
# gcloud compute networks subnets delete $CLUSTER_SUBNET_NAME

gcloud compute firewall-rules create allow-spoke-health-check --network=$SPOKE_VPC_NAME \
--action=allow --direction=ingress --source-ranges=130.211.0.0/22,35.191.0.0/16 --rules=tcp
# gcloud compute firewall-rules delete allow-spoke-health-check

gcloud compute firewall-rules create allow-spoke-proxies --network=$SPOKE_VPC_NAME \
--action=allow --direction=ingress --source-ranges=12.0.4.0/24 --rules=tcp:80,tcp:443,tcp:8080
# gcloud compute firewall-rules delete allow-spoke-proxies

gcloud compute firewall-rules create allow-spoke-internal --network=$SPOKE_VPC_NAME \
--action=allow --direction=ingress --source-ranges=12.0.6.0/28 --rules=tcp:80,tcp:443,tcp:8443,tcp:8080
#gcloud compute firewall-rules delete allow-spoke-internal

gcloud compute firewall-rules create allow-jumper-spoke-internal --network=$SPOKE_VPC_NAME \
--action=allow --direction=ingress --source-ranges=12.0.7.0/24 --rules=tcp:80,tcp:443,tcp:8443,tcp:8080
#gcloud compute firewall-rules delete allow-jumper-spoke-internal

gcloud compute addresses create gke-jump-server-ip --region=$REGION
JUMPSERERIP=$(gcloud compute addresses describe gke-jump-server-ip --format="get(address)")

gcloud container get-server-config --flatten="channels" --filter="channels.channel=REGULAR" \
    --format="yaml(channels.channel,channels.defaultVersion)"

gcloud container get-server-config --flatten="channels" --filter="channels.channel=REGULAR" \
    --format="yaml(channels.channel,channels.validVersions)"

### Jumper VM
===============
gcloud compute instances create jumper-server --image-family=debian-10 --image-project=debian-cloud \
--network=$SPOKE_VPC_NAME --subnet=$JUMP_SERVER_SUBNET_NAME --zone=$ZONE --project=$PROJECT_SPOKE
# gcloud compute instances delete jumper-server --zone=$ZONE --project=$PROJECT_SPOKE

gcloud compute instances describe jumper-server --format="get(networkInterfaces[0].networkIP)" \
--project=$PROJECT_SPOKE
gcloud compute instances describe jumper-server --format="get(networkInterfaces[0].accessConfigs[0].natIP)" \
--project=$PROJECT_SPOKE

gcloud compute ssh --zone $ZONE jumper-server --project=$PROJECT_HUB
==========================================================================================
CLUSTER_NAME="gke-private-cluster"

gcloud container clusters create $CLUSTER_NAME --release-channel=regular \
--region=$REGION --num-nodes=1 --enable-ip-alias \
--enable-master-authorized-networks --network=$SPOKE_VPC_NAME --subnetwork=$CLUSTER_SUBNET_NAME \
--cluster-secondary-range-name=pods-range --services-secondary-range-name=services-range \
--enable-master-authorized-networks --enable-private-nodes --enable-private-endpoint \
--service-account=$GSA_SPOKE \
--master-authorized-networks=$JUMPSERERIP/32 --master-ipv4-cidr=12.0.6.0/28
#gcloud container clusters delete $CLUSTER_NAME --region=$REGION

gcloud compute addresses create $REGION-nat-ip --region=$REGION
#gcloud compute addresses delete $REGION-nat-ip --region=$REGION

gcloud compute routers create rtr-$REGION --network=$SPOKE_VPC_NAME --region=$REGION
#gcloud compute routers delete rtr-$REGION --region=$REGION

gcloud compute routers nats create nat-gw-$REGION --router=rtr-$REGION --region=$REGION \
--nat-external-ip-pool=$REGION-nat-ip \
--nat-all-subnet-ip-ranges --enable-logging
#gcloud compute routers nats delete nat-gw-$REGION --router=rtr-$REGION --region=$REGION

##Access from Jump Server VM
================================
gcloud container clusters update $CLUSTER_NAME --enable-master-authorized-networks \
--master-authorized-networks=$JUMPSERERIP/32 --region=$REGION

gcloud compute ssh --zone $ZONE jumper-server --project=$PROJECT_HUB
sudo apt-get install snapd
sudo snap install core
sudo snap install kubectl --classic
sudo snap install helm --classic
sudo apt-get install google-cloud-sdk-gke-gcloud-auth-plugin

gcloud auth list
gcloud auth activate-service-account $GSA_HUB \
--key-file="./infrastructure-hub-sa.json"
gcloud config set project $PROJECT_HUB

gcloud config set account <account-name>@<dns-name>.com

gcloud projects add-iam-policy-binding $PROJECT_SPOKE \
--member="serviceAccount:$GSA_HUB" \
--role="roles/container.admin"

gcloud config set account $GSA_HUB

vi ~/.bashrc
source ~/.bashrc

gcloud container clusters get-credentials $CLUSTER_NAME --region $REGION --project=$PROJECT_SPOKE

GKE Private cluster (Approach 2)
================================
PROJECT="$PROJECT_SPOKE"
GSA="$GSA_SPOKE"

gcloud auth activate-service-account $GSA \
--key-file="${BASEFOLDERPATH}/Misc/infrastructure-spoke-sa.json"
gcloud config set project $PROJECT

gcloud compute networks create spoke-default-vpc --project=$PROJECT --subnet-mode=custom --mtu=1460 \
--bgp-routing-mode=regional
#gcloud compute networks delete spoke-default-vpc

gcloud compute firewall-rules create allow-ssh-spoke-default-rule --network spoke-default-vpc --allow tcp:22 --source-ranges=0.0.0.0/0
#gcloud compute firewall-rules delete allow-ssh-spoke-default-rule

gcloud compute networks subnets create gke-cluster-default-subnet --network=spoke-default-vpc --range=10.0.0.0/22
#gcloud compute networks subnets delete gke-cluster-default-subnet

gcloud compute networks subnets create gke-proxy-only-default-subnet --purpose=REGIONAL_MANAGED_PROXY --role=ACTIVE \
--network=spoke-default-vpc --range=10.0.4.0/24
#gcloud compute networks subnets delete gke-proxy-only-default-subnet

gcloud compute networks subnets create gke-psc-default-subnet --purpose=PRIVATE_SERVICE_CONNECT --role=ACTIVE \
--network=spoke-default-vpc --range=10.0.5.0/24
# gcloud compute networks subnets delete gke-psc-default-subnet

gcloud compute networks subnets create jumper-server-spoke-default-subnet --network=spoke-default-vpc --range=10.0.7.0/24
# gcloud compute networks subnets delete jumper-server-spoke-default-subnet

gcloud compute networks subnets update gke-cluster-default-subnet \
--add-secondary-ranges=pods-range=10.1.0.0/16,services-range=10.2.0.0/16
# gcloud compute networks subnets delete gke-cluster-default-subnet

gcloud compute firewall-rules create allow-spoke-default-health-check --network=spoke-default-vpc \
--action=allow --direction=ingress --source-ranges=130.211.0.0/22,35.191.0.0/16 --rules=tcp
# gcloud compute firewall-rules delete allow-spoke-default-health-check

gcloud compute firewall-rules create allow-spoke-proxies --network=spoke-default-vpc \
--action=allow --direction=ingress --source-ranges=10.0.4.0/24 --rules=tcp:80,tcp:443,tcp:8080
# gcloud compute firewall-rules delete allow-spoke-proxies

gcloud compute firewall-rules create allow-spoke-default-internal --network=spoke-default-vpc \
--action=allow --direction=ingress --source-ranges=10.0.6.0/28 --rules=tcp:80,tcp:443,tcp:8443,tcp:8080
#gcloud compute firewall-rules delete allow-spoke-default-internal

gcloud compute firewall-rules create allow-jumper-spoke-default-internal --network=spoke-default-vpc \
--action=allow --direction=ingress --source-ranges=10.0.7.0/24 --rules=tcp:80,tcp:443,tcp:8443,tcp:8080
#gcloud compute firewall-rules delete allow-jumper-spoke-default-internal

gcloud compute addresses create gke-jump-server-ip --region=$REGION
JUMPSERER_IP=$(gcloud compute addresses describe gke-jump-server-ip --format="get(address)")

gcloud compute addresses create gke-jump-server-private-ip --subnet=jumper-server-spoke-default-subnet \
--addresses=10.0.7.100 --region=$REGION
JUMPSERER_PRIVATE_IP=$(gcloud compute addresses describe gke-jump-server-private-ip --format="get(address)")
#gcloud compute addresses delete gke-jump-server-private-ip

### Jumper VM
===============
gcloud compute instances create jumper-server --image-family=debian-10 --image-project=debian-cloud \
--network=spoke-default-vpc --subnet=jumper-server-spoke-default-subnet --address=$JUMPSERER_IP \
--private-network-ip=$JUMPSERER_PRIVATE_IP --zone=$ZONE --project=$PROJECT_SPOKE
#gcloud compute instances delete jumper-server --zone=$ZONE --project=$PROJECT_SPOKE

gcloud compute instances describe jumper-server --format="get(networkInterfaces[0].networkIP)" \
--project=$PROJECT_SPOKE
gcloud compute instances describe jumper-server --format="get(networkInterfaces[0].accessConfigs[0].natIP)" \
--project=$PROJECT_SPOKE

gcloud compute ssh --zone $ZONE jumper-server --project=$PROJECT_HUB
==========================================================================================
gcloud container get-server-config --flatten="channels" --filter="channels.channel=REGULAR" \
    --format="yaml(channels.channel,channels.defaultVersion)"

gcloud container get-server-config --flatten="channels" --filter="channels.channel=REGULAR" \
    --format="yaml(channels.channel,channels.validVersions)"

gcloud container clusters create $CLUSTER_NAME --release-channel=regular \
--region=$REGION --num-nodes=1 --enable-ip-alias \
--enable-master-authorized-networks --network=spoke-default-vpc --subnetwork=gke-cluster-default-subnet \
--cluster-secondary-range-name=pods-range --services-secondary-range-name=services-range \
--enable-master-authorized-networks --enable-private-nodes --enable-private-endpoint \
--service-account=$GSA_SPOKE --workload-pool=$PROJECT.svc.id.goog \
--master-authorized-networks=$JUMPSERER_PRIVATE_IP/32 --master-ipv4-cidr=10.0.6.0/28
#gcloud container clusters delete $CLUSTER_NAME --region=$REGION

gcloud compute addresses create $REGION-nat-ip --region=$REGION
#gcloud compute addresses delete $REGION-nat-ip --region=$REGION

gcloud compute routers create rtr-$REGION --network=spoke-default-vpc --region=$REGION
#gcloud compute routers delete rtr-$REGION --region=$REGION

gcloud compute routers nats create nat-gw-$REGION --router=rtr-$REGION --region=$REGION \
--nat-external-ip-pool=$REGION-nat-ip --nat-all-subnet-ip-ranges --enable-logging
#gcloud compute routers nats delete nat-gw-$REGION --router=rtr-$REGION --region=$REGION
================================================================================================================================
##Access from Jump Server VM
================================
gcloud compute ssh --zone $ZONE jumper-server --project=$PROJECT_SPOKE
sudo apt-get install snapd
sudo snap install core
sudo snap install kubectl --classic
sudo snap install helm --classic
sudo apt-get install google-cloud-sdk-gke-gcloud-auth-plugin

gcloud auth list
gcloud auth activate-service-account $GSA_SPOKE --key-file="./infrastructure-spoke-sa.json"
gcloud config set compute/region $REGION
gcloud config set compute/zone $ZONE
gcloud config set project $PROJECT_SPOKE

gcloud config set account <account-name>@<dns-name>.com

gcloud projects add-iam-policy-binding $PROJECT_SPOKE --member="serviceAccount:$GSA_SPOKE" \
--role="roles/container.admin"

vi ~/.bashrc
source ~/.bashrc

gcloud container clusters get-credentials $CLUSTER_NAME --region=$REGION --project=$PROJECT
================================================================================================================================

### Deploy Applications
=========================
k apply -f ./deployments/apacheapp-deploy.yaml
k apply -f ./deployments/nginxapp-deploy.yaml

helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx
helm repo update
helm install nginx-ingress ingress-nginx/ingress-nginx -n nginx-ingress-ns --create-namespace
# helm uninstall nginx-ingress -n nginx-ingress-ns

## Public LB
=================
helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx
helm repo update

#helm install nginx-ingress ingress-nginx/ingress-nginx -n nginx-ingress-ns --create-namespace
helm install nginx-ingress ingress-nginx/ingress-nginx -n nginx-ingress-ns
#helm uninstall nginx-ingress -n nginx-ingress-ns

## Private LB
=====================================================================================
helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx
helm repo update

helm install -f ./ingress/internal-nginx-ingress-gke-config.yaml nginx-ingress ingress-nginx/ingress-nginx -n nginx-ingress-ns --create-namespace
===============================================================================================
controller:
  service:
      type: ClusterIP      
      annotations:        
        cloud.google.com/neg: '{"exposed_ports": {"443":{"name": "ingress-nginx-443-neg"}}}'
===============================================================================================

#helm install -f ./ingress/internal-nginx-ingress-config.yaml nginx-ingress ingress-nginx/ingress-nginx -n nginx-ingress-ns --create-namespace
====================================================================================================
controller:
  service:      
      loadBalancerIP: 10.0.0.100
      annotations:
        cloud.google.com/load-balancer-type: "Internal"
====================================================================================================
#helm uninstall nginx-ingress -n nginx-ingress-ns
====================================================================================================

## Private Cloud DNS Zone
==========================
gcloud dns managed-zones create $PROJECT_SPOKE-zone --dns-name internal.spoke.com. --visibility=private --networks=$SPOKE_VPC_NAME \
--description="Private Zone"
# gcloud dns managed-zones delete $PROJECT_SPOKE-zone

gcloud dns record-sets create helloapp.internal.spoke.com. --rrdatas=12.0.0.6 --type=A --ttl=60 --zone=$PROJECT_SPOKE-zone
# gcloud dns record-sets delete helloapp.internal.spoke.com --type=A --zone=$PROJECT_SPOKE-zone

gcloud dns record-sets create nginxapp.internal.spoke.com. --rrdatas=12.0.0.6 --type=A --ttl=60 --zone=$PROJECT_SPOKE-zone
# gcloud dns record-sets delete nginxapp.internal.spoke.com --type=A --zone=$PROJECT_SPOKE-zone

gcloud projects add-iam-policy-binding $PROJECT_HUB \
--member=serviceAccount:$GSA_HUB --role=roles/dns.admin

gcloud projects add-iam-policy-binding $PROJECT_SPOKE \
--member=serviceAccount:$GSA_HUB --role=roles/dns.peer

gcloud dns managed-zones create hub-spoke-dns-peer \
  --description="DNS Peering Hub to Spoke" \
  --dns-name=internal.hub.com \
  --networks=$HUB_VPC_NAME \
  --account=$GSA_HUB \
  --target-network=$SPOKE_VPC_NAME \
  --target-project=$PROJECT_SPOKE \
  --visibility=private
# gcloud dns managed-zones delete hub-spoke-dns-peer --networks=$HUB_VPC_NAME

====================================================================================================

# SSL Certificates
=====================
/*
  gcloud projects create cloud-native-creds-project
  gcloud iam service-account create cloud-native-creds-sa --display-name="SA for Certbot"

  gcloud iam service-accounts keys create \
  "/Users/monojitd/Workloads/Development/Projects/GithubProjects/Workshops/GCP-Workshop/Misc/cloud-native-creds-sa.json" \
  --iam-account=cloud-native-creds-sa@cloud-native-creds-project.iam.gserviceaccount.com

  certbot certonly --dns-google -d example.com
*/

openssl x509 -in fullchain.pem -text -noout
gcloud compute ssl-certificates create cloud-lb-cert --certificate=fullchain.pem --private-key=privkey.pem
gcloud compute ssl-certificates create cloud-lb-cert --certificate=fullchain.pem --private-key=privkey.pem --region=$REGION
# gcloud compute ssl-certificates delete --region=$REGION

Apigee X
===============

gcloud auth activate-service-account --key-file="./infrastructure-spoke-sa.json"

AUTH="Authorization: Bearer $(gcloud auth print-access-token)"
PROJECT_ID="$PROJECT_SPOKE"
RUNTIME_LOCATION="$REGION"
ANALYTICS_REGION="$REGION"

echo $AUTH
echo $PROJECT_ID
echo $RUNTIME_LOCATION
echo $ANALYTICS_REGION

gcloud compute networks subnets create gke-apigee-subnet --network=$SPOKE_VPC_NAME --range=12.0.8.0/22
# gcloud compute networks subnets delete gke-apigee-subnet

gcloud compute networks subnets create gke-apigee-troublesdhoot-subnet --network=$SPOKE_VPC_NAME --range=12.0.12.0/28
# gcloud compute networks subnets delete gke-apigee-troublesdhoot-subnet

gcloud services enable apigee.googleapis.com \
servicenetworking.googleapis.com compute.googleapis.com cloudkms.googleapis.com --project=$PROJECT_ID

APIGEE_RANGE_NAME=apigeex-svcs
APIGEE_MANAGED_RANGE_NAME=apigeex-managed-svcs
NETWORK_NAME=$SPOKE_VPC_NAME

gcloud compute addresses create $APIGEE_RANGE_NAME \
  --global \
  --prefix-length=22 \
  --network=$NETWORK_NAME --purpose=VPC_PEERING --project=$PROJECT_ID
# gcloud compute addresses delete $APIGEE_RANGE_NAME --global

gcloud compute addresses create $APIGEE_MANAGED_RANGE_NAME \
  --global \
  --prefix-length=28 \
  --network=$NETWORK_NAME --purpose=VPC_PEERING --project=$PROJECT_ID
# gcloud compute addresses delete $APIGEE_MANAGED_RANGE_NAME --global

gcloud services vpc-peerings connect \
  --service=servicenetworking.googleapis.com \
  --network=$NETWORK_NAME --ranges=$APIGEE_RANGE_NAME,$APIGEE_MANAGED_RANGE_NAME --project=$PROJECT_ID
# gcloud services vpc-peerings delete servicenetworking-googleapis-com --network=$NETWORK_NAME

gcloud alpha apigee organizations provision \
  --runtime-location=$RUNTIME_LOCATION \
  --analytics-region=$ANALYTICS_REGION \
  --authorized-network=$NETWORK_NAME --project=$PROJECT_ID
# gcloud alpha apigee organizations delete $PROJECT_SPOKE

gcloud services peered-dns-domains create gke-internal-dns --network=$SPOKE_VPC_NAME --service="servicenetworking.googleapis.com" \
--dns-suffix=internal.spoke.com.

Access from Jumper VM in Spoke
================================
gcloud compute instances create gke-jumper-client --image-family=debian-10 --image-project=debian-cloud --tags=allow-ssh \
--network=$SPOKE_VPC_NAME --subnet=$CLUSTER_SUBNET_NAME --zone=$ZONE
# gcloud compute instances delete gke-jumper-client --zone=$ZONE

gcloud compute ssh --zone $ZONE gke-jumper-client --project=$PROJECT_SPOKE

gcloud auth activate-service-account --key-file="./infrastructure-spoke-sa.json"

sudo apt-get update -y
sudo apt-get install -y jq

AUTH="Authorization: Bearer $(gcloud auth print-access-token)"
PROJECT_ID=$PROJECT_SPOKE
ENV_GROUP_HOSTNAME=$(curl -H "$AUTH" https://apigee.googleapis.com/v1/organizations/$PROJECT_ID/envgroups -s | jq -r '.environmentGroups[0].hostnames[0]')
INTERNAL_LOAD_BALANCER_IP=$(curl -H "$AUTH" https://apigee.googleapis.com/v1/organizations/$PROJECT_ID/instances -s | jq -r '.instances[0].host')

echo $AUTH
echo $PROJECT_ID
echo $ENV_GROUP_HOSTNAME
echo $INTERNAL_LOAD_BALANCER_IP

curl -i -k -H "Host: $ENV_GROUP_HOSTNAME" https://$INTERNAL_LOAD_BALANCER_IP/hello-world
==================================================================================================

Global Https LB to Apigee (External Routing)
==============================================
NEG_NAME="apigee-lb-neg"
TARGET_SERVICE="projects/nc79b28590d2f500bp-tp/regions/$REGION/serviceAttachments/apigee-$REGION-mfby"
RUNTIME_LOCATION="$REGION"
ANALYTICS_REGION="$REGION"
NETWORK_NAME="$SPOKE_VPC_NAME"
SUBNET_NAME="$PSC_SUBNET_NAME"
PROJECT_ID="$PROJECT_SPOKE"
ADDRESS_NAME="apigee-lb-address"
BACKEND_SERVICE_NAME="apigee-bkend-service"
URL_MAP_NAME="apigee-bkend-url-map"
PROXY_NAME="apigee-bkend-proxy"
FWD_RULE="apigee-fwd-rule"
CERTIFICATE="cloud-lb-cert"

gcloud compute network-endpoint-groups create $NEG_NAME \
  --network-endpoint-type=private-service-connect \
  --psc-target-service=$TARGET_SERVICE \
  --region=$RUNTIME_LOCATION \
  --network=$NETWORK_NAME \
  --subnet=$SUBNET_NAME \
  --project=$PROJECT_ID
# gcloud compute network-endpoint-groups delete $NEG_NAME --region=$RUNTIME_LOCATION

gcloud compute addresses create $ADDRESS_NAME --ip-version=IPV4 --global --project=$PROJECT_ID
# gcloud compute addresses delete $ADDRESS_NAME --global

gcloud compute addresses describe $ADDRESS_NAME --format="get(address)" --global --project=$PROJECT_ID

gcloud compute backend-services create $BACKEND_SERVICE_NAME \
  --load-balancing-scheme=EXTERNAL_MANAGED \
  --protocol=HTTPS \
  --global --project=$PROJECT_ID
# gcloud compute backend-services delete $BACKEND_SERVICE_NAME --global

gcloud compute backend-services add-backend $BACKEND_SERVICE_NAME \
  --network-endpoint-group=$NEG_NAME \
  --network-endpoint-group-region=$RUNTIME_LOCATION \
  --global --project=$PROJECT_ID

gcloud compute url-maps create $URL_MAP_NAME \
  --default-service=$BACKEND_SERVICE_NAME \
  --global --project=$PROJECT_ID
# gcloud compute url-maps delete $URL_MAP_NAME --global

gcloud compute ssl-certificates describe $CERTIFICATE \
   --global \
   --format="get(name,managed.status, managed.Status)"

gcloud compute target-https-proxies create $PROXY_NAME \
  --url-map=$URL_MAP_NAME \
  --ssl-certificates=$CERTIFICATE --project=$PROJECT_ID
# gcloud compute target-https-proxies delete $PROXY_NAME --global

gcloud compute forwarding-rules create $FWD_RULE \
  --load-balancing-scheme=EXTERNAL_MANAGED \
  --network-tier=PREMIUM \
  --address=$ADDRESS_NAME \
  --target-https-proxy=$PROXY_NAME \
  --ports=443 \
  --global --project=$PROJECT_ID
# gcloud compute forwarding-rules delete $FWD_RULE --global

curl "https://apigee.googleapis.com/v1/organizations/$PROJECT_ID/envgroups/eval-group" \
  -H "$AUTH" \
  -X PATCH \
  -H "Content-Type:application/json" \
  -d '{
    "hostnames":["'apigext.<dns-name>.com'"]
  }'

curl -H "$AUTH" \
  "https://apigee.googleapis.com/v1/organizations/$PROJECT_ID/envgroups/eval-group/attachments"

curl -i -H "$AUTH" \
  "https://apigee.googleapis.com/v1/organizations/$PROJECT_ID/environments/eval/apis/nginx-app/revisions/4/deployments"

curl -i -k https://gke-external.<dns-name>.com/hello-world

==================================================================================================

## Global Https LB to GKE Ingress (Not Working)
=================================================
/*
  gcloud compute health-checks create http app-service-80-health-check \
    --request-path / --port 80 --check-interval 60 --unhealthy-threshold 3 --healthy-threshold 1 --timeout 5
  # gcloud compute health-checks delete app-service-80-health-check

  gcloud beta compute backend-services create gke-glb-backend --load-balancing-scheme=EXTERNAL_MANAGED --protocol=HTTPS \
  --health-checks app-service-80-health-check --global
  # gcloud beta compute backend-services delete gke-glb-backend --global

  gcloud beta compute backend-services add-backend gke-glb-backend \
    --network-endpoint-group=ingress-nginx-80-neg --network-endpoint-group-zone=$REGION-c \
    --balancing-mode=RATE --capacity-scaler=1.0 --max-rate-per-endpoint=1.0 --global

  gcloud beta compute url-maps create gke-glb-map --default-service=gke-glb-backend --global
  gcloud beta compute url-maps describe gke-glb-map --format=yaml
  # gcloud beta compute url-maps delete gke-glb-map --global

  gcloud beta compute target-https-proxies create gke-glb-https-proxy --url-map=gke-glb-map \
  --ssl-certificates=cloud-lb-cert --global
  # gcloud beta compute target-https-proxies delete gke-glb-https-proxy --global

  gcloud compute addresses create gke-glb-address --ip-version=IPV4 --global
  gcloud compute addresses describe gke-glb-address --format="get(address)" --global
  # gcloud compute addresses delete gke-glb-address --global

  gcloud beta compute forwarding-rules create gke-fr-glb-endpoint \
    --load-balancing-scheme=EXTERNAL_MANAGED \
    --network-tier=PREMIUM \
    --address=gke-glb-address \
    --target-https-proxy=gke-glb-https-proxy \
    --ports=443 --global
  # gcloud beta compute forwarding-rules delete gke-fr-glb-endpoint --global

  curl -k https://gkeapps.wkshpdev.com/
*/

====================================================================================================

GKE Public Cluster
====================================================================================================
#gcloud compute instances delete jumper-server --zone=$ZONE --project=$PROJECT_HUB
PROJECT="$PROJECT_SPOKE"
GKEFOLDERPATH="$BASEFOLDERPATH/GKE"
REGION="$REGION"
CLUSTER="gke-public-cluster"
GSA="$GSA_SPOKE"

gcloud services enable container.googleapis.com --project=$PROJECT

gcloud container clusters create $CLUSTER --release-channel=regular --region=$REGION \
--enable-ip-alias --enable-autoscaling \
--num-nodes=1 --min-nodes=1 --max-nodes=3 --max-pods-per-node=40 \
--network=$SPOKE_VPC_NAME --subnetwork=$CLUSTER_SUBNET_NAME \
--cluster-secondary-range-name=pods-range --services-secondary-range-name=services-range \
--service-account=$GSA --workload-pool=$PROJECT.svc.id.goog
#gcloud container clusters delete $CLUSTER --region=$REGION

#gcloud container clusters update $CLUSTER --region=$REGION --workload-pool=$PROJECT.svc.id.goog

gcloud container node-pools create gkeappspool --cluster=$CLUSTER \
--region=$REGION --num-nodes=1 --enable-autoscaling \
--max-nodes=1 --max-pods-per-node=30
#gcloud container node-pools delete gkeappspool --cluster=$CLUSTER --region=$REGION

gcloud container clusters get-credentials $CLUSTER --region=$REGION --project=$PROJECT

## Public LB
=================
helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx
helm repo update

#helm install nginx-ingress ingress-nginx/ingress-nginx -n nginx-ingress-ns --create-namespace
helm install nginx-ingress ingress-nginx/ingress-nginx -n nginx-ingress-ns
#helm uninstall nginx-ingress -n nginx-ingress-ns

## Private LB
=================
helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx
helm repo update

#helm install -f internal-ingress-config.yaml nginx-ingress ingress-nginx/ingress-nginx -n nginx-ingress-ns --create-namespace
#helm install -f $GKEFOLDERPATH/general/ingress/internal-nginx-ingress-gke-config.yaml nginx-ingress ingress-nginx/ingress-nginx -n nginx-ingress-ns --create-namespace
helm install -f $GKEFOLDERPATH/general/ingress/internal-nginx-ingress-config.yaml nginx-ingress ingress-nginx/ingress-nginx -n nginx-ingress-ns --create-namespace
#helm uninstall nginx-ingress -n nginx-ingress-ns

Jump Server (Spoke)
============================
INTERNAL_LB_IP="12.0.0.100"
PROXY_VM=gke-nginx-proxy

gcloud compute instances create-with-container $PROXY_VM \
   --zone=$ZONE \
   --network=$SPOKE_VPC_NAME --subnet=$JUMP_SERVER_SUBNET_NAME \
   --container-image gcr.io/cloud-marketplace/google/nginx:latest \
   --container-mount-host-path=host-path=/tmp/server.conf,mount-path=/etc/nginx/conf.d/default.conf \
   --metadata=startup-script="#! /bin/bash
     cat <<EOF  > /tmp/server.conf
     server {
         listen 8080;
         location /apache {
             proxy_pass http://apacheapp.internal.spoke.com;
         }
         location /nginx {
             proxy_pass http://nginxapp.internal.spoke.com;
         }
     }
EOF"
#gcloud compute instances delete $PROXY_VM --zone $ZONE

gcloud compute ssh --zone $ZONE $PROXY_VM -- -L 8089:localhost:8080

## Deploy microservices
=========================
go install github.com/google/go-containerregistry/cmd/gcrane@latest

gcrane cp gcr.io/google-samples/microservices-demo/adservice:v0.3.6 \
$REGION-docker.pkg.dev/$PROJECT_SPOKE/cloud-native-repo/adservice:v0.3.6

gcrane cp gcr.io/google-samples/microservices-demo/cartservice:v0.3.6 \
$REGION-docker.pkg.dev/$PROJECT_SPOKE/cloud-native-repo/cartservice:v0.3.6

gcrane cp gcr.io/google-samples/microservices-demo/checkoutservice:v0.3.6 \
$REGION-docker.pkg.dev/$PROJECT_SPOKE/cloud-native-repo/checkoutservice:v0.3.6

gcrane cp gcr.io/google-samples/microservices-demo/currencyservice:v0.3.6 \
$REGION-docker.pkg.dev/$PROJECT_SPOKE/cloud-native-repo/currencyservice:v0.3.6

gcrane cp gcr.io/google-samples/microservices-demo/emailservice:v0.3.6 \
$REGION-docker.pkg.dev/$PROJECT_SPOKE/cloud-native-repo/emailservice:v0.3.6

gcrane cp gcr.io/google-samples/microservices-demo/frontend:v0.3.6 \
$REGION-docker.pkg.dev/$PROJECT_SPOKE/cloud-native-repo/frontend:v0.3.6

gcrane cp gcr.io/google-samples/microservices-demo/loadgenerator:v0.3.6 \
$REGION-docker.pkg.dev/$PROJECT_SPOKE/cloud-native-repo/loadgenerator:v0.3.6

gcrane cp gcr.io/google-samples/microservices-demo/paymentservice:v0.3.6 \
$REGION-docker.pkg.dev/$PROJECT_SPOKE/cloud-native-repo/paymentservice:v0.3.6

gcrane cp gcr.io/google-samples/microservices-demo/productcatalogservice:v0.3.6 \
$REGION-docker.pkg.dev/$PROJECT_SPOKE/cloud-native-repo/productcatalogservice:v0.3.6

gcrane cp gcr.io/google-samples/microservices-demo/recommendationservice:v0.3.6 \
$REGION-docker.pkg.dev/$PROJECT_SPOKE/cloud-native-repo/recommendationservice:v0.3.6

gcrane cp gcr.io/google-samples/microservices-demo/shippingservice:v0.3.6 \
$REGION-docker.pkg.dev/$PROJECT_SPOKE/cloud-native-repo/shippingservice:v0.3.6

k apply -f ./namespaces/
#k delete -f ./namespaces/

k apply -f ./deployments/
#k delete -f ./deployments/

k apply -f ./services/
#k delete -f ./services/

k apply -f ./ingress/frontend-ingress.yaml
#k delete -f ./ingress/frontend-ingress.yaml

k apply -f ./general/helloworld-app-v2.yaml
#k delete -f ./general/helloworld-app-v2.yaml

k apply -f ./general/ingress/helloworld-app-v2-ingress.yaml
#k delete -f ./general/ingress/helloworld-app-v2-ingress.yaml

gcloud compute network-endpoint-groups list
SSL Secrets
============
k create secret tls gke-ingress-cert --cert="./Misc/Certs/<dns-name>.com/fullchain.pem" \
--key="./Misc/Certs/<dns-name>.com/privkey.pem"

Regional Http LB to GKE (through Private Service Connect)
=======================================================================
gcloud compute forwarding-rules list

gcloud compute service-attachments create gke-ingress-attachment --region=$REGION \
--producer-forwarding-rule=a487a9f46f4c74ba28bb366f60911f20 --connection-preference=ACCEPT_AUTOMATIC \
--nat-subnets=$PSC_SUBNET_NAME
#gcloud compute service-attachments delete gke-ingress-attachment

gcloud compute network-endpoint-groups create gke-glb-neg \
  --network-endpoint-type=private-service-connect \
  --psc-target-service=$(gcloud compute service-attachments describe gke-ingress-attachment --region=$REGION \
  --format="get(selfLink)") \
   --network=$SPOKE_VPC_NAME \
  --subnet=$PSC_SUBNET_NAME \
  --region=$REGION
#gcloud compute network-endpoint-groups delete gke-glb-neg --region=$REGION
====================================================================================================

Global Https LB to Nginx Ingress (through Private Service Connect)
=======================================================================

INGRESS_SERVICE_ATTACHMENT="nginx-ingress-attachment"
#INGRESS_SERVICE_ATTACHMENT="gke-ingress-attachment"

gcloud compute service-attachments create $INGRESS_SERVICE_ATTACHMENT --region=$REGION \
--producer-forwarding-rule=a4787838a217547bd887b44a20088d4e --connection-preference=ACCEPT_AUTOMATIC \
--nat-subnets=$PSC_SUBNET_NAME
#gcloud compute service-attachments delete $INGRESS_SERVICE_ATTACHMENT

gcloud compute network-endpoint-groups create gke-glb-neg \
  --network-endpoint-type=private-service-connect \
  --psc-target-service=$(gcloud compute service-attachments describe ${INGRESS_SERVICE_ATTACHMENT} --region=$REGION \
  --format="get(selfLink)") \
   --network=$SPOKE_VPC_NAME \
  --subnet=$PSC_SUBNET_NAME \
  --region=$REGION
#gcloud compute network-endpoint-groups delete gke-glb-neg --region=$REGION

gcloud compute addresses create gke-glb-address --ip-version=IPV4 --global
gcloud compute addresses describe gke-glb-address --format="get(address)" --global
# gcloud compute addresses delete gke-glb-address --global

gcloud compute backend-services create gke-glb-backend --load-balancing-scheme=EXTERNAL_MANAGED --protocol=HTTP --global
# gcloud compute backend-services delete gke-glb-backend --global

gcloud compute backend-services add-backend gke-glb-backend \
  --network-endpoint-group=gke-glb-neg --network-endpoint-group-region=$REGION --global

gcloud compute url-maps create gke-glb-map --default-service=gke-glb-backend --global
gcloud compute url-maps describe gke-glb-map --format=yaml
gcloud compute url-maps import gke-glb-map --source=./gke-glb-map.yaml --global
# gcloud compute url-maps delete gke-glb-map --global

gcloud compute target-https-proxies create gke-glb-https-proxy --url-map=gke-glb-map --ssl-certificates=cloud-lb-cert --global
# gcloud compute target-https-proxies delete gke-glb-https-proxy --global

gcloud compute target-http-proxies create gke-glb-http-proxy --url-map=gke-glb-map --global
# gcloud compute target-http-proxies delete gke-glb-http-proxy --global

gcloud compute forwarding-rules create gke-fr-glb-endpoint \
  --load-balancing-scheme=EXTERNAL_MANAGED \
  --network-tier=PREMIUM \
  --address=gke-glb-address \
  --target-https-proxy=gke-glb-https-proxy \
  --ports=443 --global
# gcloud compute forwarding-rules delete gke-fr-glb-endpoint --globals
==========================================================================================================================================

Global Https LB to Service Mesh Gateway (through Private Service Connect)
===========================================================================
gcloud auth activate-service-account infrastructure-spoke-sa@cloud-native-spoke.iam.gserviceaccount.com \
--key-file=./infrastructure-spoke-sa.json

gcloud services enable mesh.googleapis.com

#Run this in Cloud Shell
==========================
REGION="$REGION"
PROJECT="cloud-native-spoke"
CLUSTER="gke-public-cluster"
GSA="infrastructure-spoke-sa@cloud-native-spoke.iam.gserviceaccount.com"

curl https://storage.googleapis.com/csm-artifacts/asm/asmcli_1.15 > asmcli

gcloud container clusters get-credentials $CLUSTER --region=$REGION --project=$PROJECT
kubectl create clusterrolebinding cluster-admin-binding --clusterrole=cluster-admin --user=$GSA
mkdir asmmesh

./asmcli validate \
  --project_id $PROJECT \
  --cluster_name $CLUSTER \
  --cluster_location $REGION \
  --fleet_id $PROJECT

chmod +x asmcli
./asmcli install \
  --project_id $PROJECT --cluster_name $CLUSTER \
  --cluster_location $REGION --fleet_id $PROJECT \
  --output_dir asmmesh \
  --ca mesh_ca --enable_all 
==========================
Back to MAC CLI
=================
ISTIOPATH="$GKEFOLDERPATH/asm/product-catalogue/istio-manifests"
INGRESS_SERVICE_ATTACHMENT="nginx-ingress-attachment"

k create namespace asm-ngw-ns
k label namespace asm-ngw-ns istio-injection=enabled

k apply -f $GKEFOLDERPATH/asm/gateways/istio-ingressgateway -n asm-ngw-ns
#k delete -f $GKEFOLDERPATH/asm/gateways/istio-ingressgateway -n asm-ngw-ns

k apply -f $GKEFOLDERPATH/asm/gateways/istio-egressgateway -n asm-ngw-ns
#k delete -f $GKEFOLDERPATH/asm/gateways/istio-egressgateway -n asm-ngw-ns

#Secret for TLS for all namespaces
k create secret tls primary-tls-secret -n asm-ngw-ns --cert="$BASEFOLDERPATH/Misc/Certs/<dns-name>.com/fullchain.pem" --key="$BASEFOLDERPATH/Misc/Certs/<dns-name>.com/privkey.pem"
#k delete secret primary-tls-secret -n asm-ngw-ns

gcloud compute service-attachments create $INGRESS_SERVICE_ATTACHMENT --region=$REGION \
--producer-forwarding-rule=ab01711818d9c431a96d0f0019a62d13 --connection-preference=ACCEPT_AUTOMATIC \
--nat-subnets=$PSC_SUBNET_NAME
#gcloud compute service-attachments delete $INGRESS_SERVICE_ATTACHMENT

gcloud compute network-endpoint-groups create gke-glb-neg \
  --network-endpoint-type=private-service-connect \
  --psc-target-service=$(gcloud compute service-attachments describe ${INGRESS_SERVICE_ATTACHMENT} --region=$REGION \
  --format="get(selfLink)") \
   --network=$SPOKE_VPC_NAME \
  --subnet=$PSC_SUBNET_NAME \
  --region=$REGION
#gcloud compute network-endpoint-groups delete gke-glb-neg --region=$REGION

gcloud dns managed-zones update cloud-native-spoke-zone --networks=$SPOKE_VPC_NAME,asm-vpc \
--description="Private Zone"
# gcloud dns managed-zones delete cloud-native-spoke-zone

gcloud dns record-sets create smoke-mesh.internal.spoke.com. --rrdatas=14.0.0.100 --type=A --ttl=60 \
--zone=cloud-native-spoke-zone
# gcloud dns record-sets delete smoke-mesh.internal.spoke.com. --type=A --zone=cloud-native-spoke-zone

gcloud dns record-sets create primary-mesh.internal.spoke.com. --rrdatas=14.0.0.100 --type=A --ttl=60 \
--zone=cloud-native-spoke-zone
# gcloud dns record-sets delete primary-mesh.internal.spoke.com. --type=A --zone=cloud-native-spoke-zone

k create ns smoke
k label namespace smoke istio-injection=enabled
k label namespace istio-system istio-injection=enabled

helm upgrade --install --create-namespace smoke-tests-chart $GKEFOLDERPATH/asm/product-catalogue/smoke/smoke-tests-chart/ -n smoke \
-f $GKEFOLDERPATH/asm/product-catalogue/smoke/smoke-tests-chart/values-smoke.yaml
#helm uninstall smoke-tests-chart -n smoke

k apply -f $ISTIOPATH/smoke-gateway.yaml -n smoke
#k delete -f $ISTIOPATH/smoke-gateway.yaml -n smoke

k create serviceaccount gke-smoke-sa -n smoke
gcloud iam service-accounts add-iam-policy-binding $GSA \
    --role=roles/iam.workloadIdentityUser \
    --member="serviceAccount:$PROJECTID.svc.id.goog[default/gke-identity-sa]"
k annotate serviceaccount gke-smoke-sa -n smoke iam.gke.io/gcp-service-account=$GSA
curl -H "Metadata-Flavor: Google" http://169.254.169.254/computeMetadata/v1/instance/service-accounts/default/email

#Secret for TLS for all namespaces
k create secret tls primary-tls-secret -n asm-ngw-ns --cert="$ROOTPATH/misc/certs/<dns-name>.com/fullchain.pem" --key="$ROOTPATH/misc/certs/<dns-name>.com/privkey.pem"
#k delete secret primary-tls-secret -n asm-ngw-ns

k apply -f $BASEPATH/addons
#k delete -f $BASEPATH/addons

#k apply -f $ISTIOPATH/kiali-gateway.yaml -n istio-system
#k delete -f $ISTIOPATH/kiali-gateway.yaml -n istio-system

k create ns primary
k label namespace primary istio-injection=enabled
k apply -f $BASEPATH/product-catalogue/bookinfo/ -n primary
#k delete -f $BASEPATH/product-catalogue/bookinfo/ -n primary

k apply -f $ISTIOPATH/primary-gateway.yaml -n primary
#k delete -f $ISTIOPATH/primary-gateway.yaml -n primary

k apply -f $BASEPATH/product-catalogue/bluegreen/ -n primary
#k delete -f $BASEPATH/product-catalogue/bluegreen/ -n primary
k apply -f $ISTIOPATH/podinfo-destination-rule.yaml -n primary
#k delete -f $ISTIOPATH/podinfo-destination-rule.yaml -n primary

k apply -f $BASEPATH/product-catalogue/helloworld/ -n primary
#k delete -f $BASEPATH/product-catalogue/helloworld/ -n primary
k apply -f $ISTIOPATH/helloworld-destination-rule.yaml -n primary
#k delete -f $ISTIOPATH/helloworld-destination-rule.yaml -n primary
fortio load -c 5 -qps 0 -n 30 -loglevel Warning http://primary-mesh.<dns-name>.com/hello

k apply -f $BASEPATH/product-catalogue/httpbin/httpbin.yaml -n primary
#k delete -f $BASEPATH/product-catalogue/httpbin/httpbin.yaml -n primary
k apply -f $ISTIOPATH/httpbin-destination-rule.yaml -n primary
#k delete -f $ISTIOPATH/httpbin-destination-rule.yaml -n primary
fortio load -c 1 -qps 0 -n 10 -loglevel Warning http://primary-mesh.<dns-name>.com/httpbin
fortio load -c 2 -qps 0 -n 20 -loglevel Warning http://primary-mesh.<dns-name>.com/httpbin
fortio load -c 4 -qps 0 -n 20 -loglevel Warning http://primary-mesh.<dns-name>.com/httpbin
fortio load -c 7 -qps 0 -n 20 -loglevel Warning http://primary-mesh.<dns-name>.com/httpbin

#k apply -f $ISTIOPATH/primary-serviceentry.yaml -n primary
#k delete -f $ISTIOPATH/primary-serviceentry.yaml -n primary

Uninstall asm
==============
k get namespace <namespace> --show-labels
k label namespace <namespace> istio.io/rev-
k label namespace <namespace> istio-injection-
k delete controlplanerevision -n istio-system
k delete validatingwebhookconfiguration,mutatingwebhookconfiguration -l operator.istio.io/component=Pilot
istioctl x uninstall --purge
k delete namespace istio-system asm-system --ignore-not-found=true
==========================================================================================================================================


Traffic Director
====================
ZONE="$REGION-a"
NEWORK="$SPOKE_VPC_NAME"
SUBNEWORK="$CLUSTER_SUBNET_NAME"

gcloud services enable trafficdirector.googleapis.com
gcloud services enable dns.googleapis.com

gcloud container clusters create traffic-director-cluster \
  --zone=$ZONE \
  --num-nodes=3 \
  --scopes=https://www.googleapis.com/auth/cloud-platform \
  --enable-ip-alias --workload-pool=$PROJECT_SPOKE.svc.id.goog \
  # --cluster-version=1.24.2-gke.1900

# gcloud container clusters delete traffic-director-cluster --zone=$ZONE
# gcloud container clusters resize traffic-director-cluster --zone=$ZONE --num-nodes=3
gcloud container clusters get-credentials traffic-director-cluster --zone $ZONE
gcloud container clusters list

Workload Identity for New cluster
========================================
gcloud container clusters update traffic-director-cluster \
    --zone=$REGION-a \
    --workload-pool=$PROJECT_SPOKE.svc.id.goog

gcloud container node-pools update default-pool \
    --cluster=traffic-director-cluster \
    --workload-metadata=GKE_METADATA --zone=$REGION-a

kubectl create serviceaccount gke-identity-sa

gcloud projects add-iam-policy-binding $PROJECT_SPOKE \
    --member="serviceAccount:$GSA_SPOKE" \
    --role="roles/trafficdirector.client"

gcloud iam service-accounts add-iam-policy-binding $GSA_SPOKE \
    --role=roles/iam.workloadIdentityUser \
    --member="serviceAccount:$PROJECT_SPOKE.svc.id.goog[default/gke-identity-sa]"

kubectl annotate serviceaccount gke-identity-sa \
    --namespace default \
    iam.gke.io/gcp-service-account=$GSA_SPOKE

curl -H "Metadata-Flavor: Google" http://169.254.169.254/computeMetadata/v1/instance/service-accounts/default/email
wget --header="Metadata-Flavor: Google" http://169.254.169.254/computeMetadata/v1/instance/service-accounts/default/email

========================================

curl -o ./td-sidecar-injector-xdsv3.tgz  https://storage.googleapis.com/traffic-director/td-sidecar-injector-xdsv3.tgz
tar -xzvf td-sidecar-injector-xdsv3.tgz
cd td-sidecar-injector-xdsv3

openssl genrsa -out ../key.pem 2048
openssl req -new -key ../key.pem -out ../td-cert.csr -config ../td-ossl-conf.txt
openssl x509 -req -signkey ../key.pem -in ../td-cert.csr -out ../cert.pem -extfile ../td-ossl-conf.txt \
-extensions extension_requirements -days 360
cp ../cert.pem ../ca-cert.pem

/*
CN=istio-sidecar-injector.istio-control.svc
openssl req \
  -x509 \
  -newkey rsa:4096 \
  -keyout key.pem \
  -out cert.pem \
  -days 365 \
  -nodes \
  -subj "/CN=${CN}"
# -addext "subjectAltName=DNS:${CN}"
# cp cert.pem ca-cert.pem
*/

vi specs/01-configmap.yaml
kubectl apply -f specs/00-namespaces.yaml
# kubectl delete -f specs/00-namespaces.yaml

kubectl create secret generic istio-sidecar-injector -n istio-control \
  --from-file="../cert.pem" --from-file="../key.pem" --from-file="../ca-cert.pem"
# kubectl delete secret istio-sidecar-injector -n istio-control

CA_BUNDLE=$(cat "cert.pem" | base64 | tr -d '\n')
sed -i "s/caBundle:.*/caBundle:\ ${CA_BUNDLE}/g" specs/02-injector.yaml

kubectl apply -f specs/
# kubectl delete -f specs/

kubectl get pods -A -w | grep sidecar-injector

kubectl label namespace default istio-injection=enabled
# kubectl label namespace default istio-injection-
kubectl get namespace -L istio-injection

kubectl apply -f ./demo/client_sample.yaml
# kubectl delete -f ./demo/client_sample.yaml

curl -o ./trafficdirector_service_sample.yaml https://storage.googleapis.com/traffic-director/demo/trafficdirector_service_sample.yaml
kubectl apply -f ./demo/trafficdirector_service_sample.yaml
# kubectl delete -f ./demo/trafficdirector_service_sample.yaml

gcloud compute network-endpoint-groups list
# gcloud compute network-endpoint-groups delete service-test-neg --zone=$REGION-a

gcloud compute health-checks create http td-gke-health-check --use-serving-port
# gcloud compute health-checks delete td-gke-health-check 
gcloud compute firewall-rules create fw-allow-health-checks \
  --action ALLOW \
  --direction INGRESS \
  --source-ranges 35.191.0.0/16,130.211.0.0/22 \
  --rules tcp
# gcloud compute firewall-rules delete fw-allow-health-checks

gcloud compute backend-services create td-gke-service \
 --global \
 --health-checks td-gke-health-check \
 --load-balancing-scheme=INTERNAL_SELF_MANAGED
# gcloud compute backend-services delete td-gke-service --global

gcloud compute backend-services add-backend td-gke-service \
 --global \
 --network-endpoint-group=service-test-neg \
 --network-endpoint-group-zone=$REGION-a \
 --balancing-mode=RATE \
 --max-rate-per-endpoint 5

gcloud compute url-maps create td-gke-url-map --default-service td-gke-service
# gcloud compute url-maps delete td-gke-url-map

gcloud compute url-maps add-path-matcher td-gke-url-map --default-service td-gke-service \
--path-matcher-name td-gke-path-matcher

gcloud compute url-maps add-host-rule td-gke-url-map --hosts service-test \
--path-matcher-name td-gke-path-matcher

gcloud compute target-http-proxies create td-gke-proxy --url-map td-gke-url-map
# gcloud compute target-http-proxies delete td-gke-proxy

gcloud compute forwarding-rules create td-gke-forwarding-rule \
  --global \
  --load-balancing-scheme=INTERNAL_SELF_MANAGED \
  --address=0.0.0.0 \
  --target-http-proxy=td-gke-proxy \
  --ports 80 --network=default
# gcloud compute forwarding-rules delete td-gke-forwarding-rule --global

BUSYBOX_POD=$(kubectl get po -l run=client -o=jsonpath='{.items[0].metadata.name}')

# Command to execute that tests connectivity to the service service-test at
# the VIP 10.0.0.1. Because 0.0.0.0 is configured in the forwarding rule, this
# can be any VIP.
TEST_CMD="wget -q -O - 10.0.0.1; echo"

# Execute the test command on the pod.
kubectl exec -it $BUSYBOX_POD -c busybox -- /bin/sh -c "$TEST_CMD"

gcloud compute --project $PROJECT_SPOKE instances get-guest-attributes gke-traffic-director-clu-default-pool-c7175283-5o7i \
  --zone=$REGION-a --query-path=td-gke-proxy/proxy-version
================================================================================

Traffic Director for VMs
========================================
gcloud services enable osconfig.googleapis.com

gcloud compute instance-templates create td-demo-hello-world-template \
  --machine-type=n1-standard-1 \
  --boot-disk-size=20GB \
  --image-family=debian-10  \
  --image-project=debian-cloud \
  --scopes=https://www.googleapis.com/auth/cloud-platform \
  --tags=td-http-server \
  --service-proxy=enabled \
  --metadata=startup-script="#! /bin/bash
sudo apt-get update -y
sudo apt-get install apache2 -y
sudo service apache2 restart
sudo mkdir -p /var/www/html/
echo '<!doctype html><html><body><h1>'\`/bin/hostname\`'</h1></body></html>' | sudo tee /var/www/html/index.html"
# gcloud compute instance-templates delete td-demo-hello-world-template

 gcloud compute instance-groups managed create td-demo-hello-world-mig \
  --zone us-central1-a \
  --size=2 \
  --template=td-demo-hello-world-template
# gcloud compute instance-groups managed delete td-demo-hello-world-mig --zone us-central1-a

gcloud compute health-checks create http td-vm-health-check
# gcloud compute health-checks delete http td-vm-health-check

gcloud compute firewall-rules create fw-allow-health-checks \
  --action ALLOW \
  --direction INGRESS \
  --source-ranges 35.191.0.0/16,130.211.0.0/22 \
  --target-tags td-http-server \
  --rules tcp:80

gcloud compute backend-services create td-vm-service \
 --global \
 --load-balancing-scheme=INTERNAL_SELF_MANAGED \
 --connection-draining-timeout=30s \
 --health-checks td-vm-health-check
# gcloud compute backend-services delete td-vm-service --global

gcloud compute backend-services add-backend td-vm-service \
  --instance-group td-demo-hello-world-mig \
  --instance-group-zone us-central1-a \
  --global

gcloud compute url-maps create td-vm-url-map --default-service td-vm-service
# gcloud compute url-maps delete td-vm-url-map

gcloud compute url-maps add-path-matcher td-vm-url-map \
   --default-service td-vm-service \
   --path-matcher-name td-vm-path-matcher
gcloud compute url-maps add-host-rule td-vm-url-map \
   --path-matcher-name=td-vm-path-matcher \
   --hosts=hello-world

gcloud compute target-http-proxies create td-vm-proxy --url-map=td-vm-url-map
# gcloud compute target-http-proxies delete td-vm-proxy

gcloud compute forwarding-rules create td-vm-forwarding-rule \
   --global \
   --load-balancing-scheme=INTERNAL_SELF_MANAGED \
   --address=10.0.0.1 \
   --target-http-proxy=td-vm-proxy \
   --ports=80 \
   --network=default
# gcloud compute forwarding-rules delete td-vm-forwarding-rule --global
curl -H "Host: hello-world" http://10.0.0.1/
========================================================================================================================

Workload Identity for Existing cluster
========================================
gcloud container clusters update $CLUSTER_NAME \
    --region=$REGION \
    --workload-pool=$PROJECT_SPOKE.svc.id.goog

gcloud container node-pools update default-pool \
    --cluster=$CLUSTER_NAME \
    --workload-metadata=GKE_METADATA --region=$REGION 

kubectl create serviceaccount gke-identity-sa

gcloud projects add-iam-policy-binding $PROJECT_SPOKE \
    --member="serviceAccount:$GSA_SPOKE" \
    --role="roles/trafficdirector.client"

gcloud iam service-accounts add-iam-policy-binding $GSA_SPOKE \
    --role=roles/iam.workloadIdentityUser \
    --member="serviceAccount:$PROJECT_SPOKE.svc.id.goog[default/gke-identity-sa]"

kubectl annotate serviceaccount gke-identity-sa \
    --namespace default \
    iam.gke.io/gcp-service-account=$GSA_SPOKE

curl -H "Metadata-Flavor: Google" http://169.254.169.254/computeMetadata/v1/instance/service-accounts/default/email
wget --header="Metadata-Flavor: Google" http://169.254.169.254/computeMetadata/v1/instance/service-accounts/default/email
============================================================================================================================

Artifact Registry
==========================================================================================
gcloud services enable artifactregistry.googleapis.com
gcloud artifacts repositories create cloud-native-repo --location=$REGION --repository-format=docker
#gcloud artifacts repositories delete cloud-native-repo --location=$REGION
gcloud artifacts repositories list

gcloud auth configure-docker $REGION-docker.pkg.dev

docker pull us-docker.pkg.dev/google-samples/containers/gke/hello-app:1.0
docker tag us-docker.pkg.dev/google-samples/containers/gke/hello-app:1.0 $REGION-docker.pkg.dev/$PROJECT_SPOKE/cloud-native-repo/hello-app:v1.0
docker push $REGION-docker.pkg.dev/$PROJECT_SPOKE/cloud-native-repo/hello-app:v1.0

docker pull --platform=linux/amd64 nginx:latest
docker tag nginx:latest $REGION-docker.pkg.dev/$PROJECT_SPOKE/cloud-native-repo/nginx-app:v1.0
docker push $REGION-docker.pkg.dev/$PROJECT_SPOKE/cloud-native-repo/nginx-app:v1.0

docker build -t $REGION-docker.pkg.dev/$PROJECT_SPOKE/cloud-native-repo/ratings-api:v1.0.0 .
docker push $REGION-docker.pkg.dev/$PROJECT_SPOKE/cloud-native-repo/ratings-api:v1.0.0

docker build -t $REGION-docker.pkg.dev/$PROJECT_SPOKE/cloud-native-repo/ratings-web:v1.0.0 .
docker push $REGION-docker.pkg.dev/$PROJECT_SPOKE/cloud-native-repo/ratings-web:v1.0.0

# gcloud auth print-access-token | docker login -u oauth2accesstoken --password-stdin https://$REGION-docker.pkg.dev

gcloud artifacts docker images list $REGION-docker.pkg.dev/$PROJECT_SPOKE/cloud-native-repo
# gcloud artifacts docker images delete $REGION-docker.pkg.dev/$PROJECT_SPOKE/cloud-native-repo/hello-app
# gcloud artifacts docker images delete $REGION-docker.pkg.dev/$PROJECT_SPOKE/cloud-native-repo/nginx-app
# gcloud artifacts docker images delete $REGION-docker.pkg.dev/$PROJECT_SPOKE/cloud-native-repo/ratings-web
# gcloud artifacts docker images delete $REGION-docker.pkg.dev/$PROJECT_SPOKE/cloud-native-repo/ratings-api

Keycloak
=============================================
docker run -d -p 8080:8080 -e KEYCLOAK_ADMIN=admin -e KEYCLOAK_ADMIN_PASSWORD=admin quay.io/keycloak/keycloak:19.0.2 start-dev

==================================================================================================
==================================================================================================
                                    Archived                                                      
==================================================================================================
==================================================================================================













Old Approach
====================================================================================================
# Service Accounts
=========================
gcloud iam service-accounts keys \
create "/Users/monojitd/Workloads/Development/Projects/GithubProjects/Workshops/GCP-Workshop/Misc/cloud-native-workshop-sa.json" \
--iam-account=cloud-native-workshop-sa@cloud-native-workshop.iam.gserviceaccount.com

gcloud projects add-iam-policy-binding cloud-native-workshop --member="serviceAccount:cloud-native-workshop-sa@cloud-native-workshop.iam.gserviceaccount.com" --role="roles/owner"

gcloud auth activate-service-account --key-file="/Users/monojitd/Workloads/Development/Projects/GithubProjects/Workshops/GCP-Workshop/Misc/cloud-native-workshop-sa.json"
gcloud config set account cloud-native-workshop-sa@cloud-native-workshop.iam.gserviceaccount.com 
gcloud config set compute/region $REGION

gcloud compute networks create cloud-native-vpc --project=cloud-native-workshop --subnet-mode=custom --mtu=1460 \
--bgp-routing-mode=regional

gcloud compute networks subnets create linux-vm-subnet --project=cloud-native-workshop --range=11.0.0.0/16 \
--stack-type=IPV4_ONLY --network=cloud-native-vpc --region=$REGION

Regional LB
==============================================================================================================================

gcloud compute networks create cloud-native-vpc --subnet-mode=custom
gcloud compute firewall-rules create allow-all-rule --network cloud-native-vpc --allow tcp,udp,icmp --source-ranges=0.0.0.0/0
gcloud compute networks subnets create cloud-lb-subnet --network=cloud-native-vpc --range=11.0.0.0/24

gcloud compute instances create cloud-lb-vm --network=cloud-native-vpc --subnet=cloud-lb-subnet --zone=$ZONE
# gcloud compute instances delete cloud-lb-vm --zone=$ZONE

gcloud compute networks subnets create proxy-only-subnet --purpose=REGIONAL_MANAGED_PROXY --role=ACTIVE \
--network=cloud-native-vpc --range=11.0.1.0/24
# gcloud compute networks subnets delete proxy-only-subnet

gcloud compute addresses create cloud-lb-address --network-tier=STANDARD
# gcloud compute addresses delete cloud-lb-address

gcloud compute network-endpoint-groups create today-serverless-neg --region=$REGION --network-endpoint-type=serverless \
--cloud-run-service=today-cloud-run
# gcloud compute network-endpoint-groups delete today-serverless-neg --region=$REGION

gcloud compute network-endpoint-groups create tomorrow-serverless-neg --region=$REGION --network-endpoint-type=serverless \
--cloud-run-service=tomorrow-cloud-run
# gcloud compute network-endpoint-groups delete tomorrow-serverless-neg --region=$REGION

gcloud beta compute backend-services create today-service-backend --load-balancing-scheme=EXTERNAL_MANAGED --protocol=HTTP \
--region=$REGION
# gcloud beta compute backend-services delete today-service-backend --region=$REGION
gcloud beta compute backend-services add-backend today-service-backend --region=$REGION \
--network-endpoint-group=today-serverless-neg --network-endpoint-group-region=$REGION

gcloud beta compute backend-services create tomorrow-service-backend --load-balancing-scheme=EXTERNAL_MANAGED --protocol=HTTP \
--region=$REGION
# gcloud beta compute backend-services delete tomorrow-service-backend --region=$REGION
gcloud beta compute backend-services add-backend tomorrow-service-backend --region=$REGION \
--network-endpoint-group=tomorrow-serverless-neg --network-endpoint-group-region=$REGION
    
gcloud beta compute url-maps create cloud-native-map --default-service=today-service-backend --region=$REGION
OR, 
gcloud beta compute url-maps import cloud-native-map  --source=./LoadBalancer/url-map.yaml --region=$REGION
# gcloud beta compute url-maps delete cloud-native-map --region=$REGION

gcloud beta compute target-http-proxies create cloud-lb-http-proxy --url-map=cloud-native-map --region=$REGION
# gcloud beta compute target-http-proxies delete cloud-lb-http-proxy --region=$REGION

gcloud beta compute forwarding-rules create cloud-lb-forwarding-rule \
--load-balancing-scheme=EXTERNAL_MANAGED --network-tier=STANDARD --network=cloud-native-vpc \
--address=cloud-lb-address --target-http-proxy=cloud-lb-http-proxy --target-http-proxy-region=$REGION \
--region=$REGION --ports=80

# gcloud beta compute forwarding-rules delete cloud-lb-forwarding-rule --region=$REGION
    
curl -H "Authorization: Bearer $(gcloud auth print-identity-token)" http://35.213.144.186.nip.io/cr


Global LB
==============================================================================================================================

gcloud compute networks create cloud-native-vpc --subnet-mode=custom
gcloud compute firewall-rules create allow-all-rule --network cloud-native-vpc --allow tcp,udp,icmp --source-ranges=0.0.0.0/0
gcloud compute networks subnets create cloud-lb-subnet --network=cloud-native-vpc --range=11.0.0.0/24

gcloud compute ssl-certificates create cloud-lb-cert --certificate=./Misc/Certs/wkshpdev.com/fullchain.pem \
--private-key=./Misc/Certs/wkshpdev.com/privkey.pem
#gcloud compute ssl-certificates delete cloud-lb-cert

gcloud compute addresses create cloud-lb-address --ip-version=IPV4 --network-tier=PREMIUM --global
gcloud compute addresses describe cloud-lb-address --format="get(address)" --global
# gcloud compute addresses delete cloud-lb-address --global

gcloud compute network-endpoint-groups create today-serverless-neg --region=$REGION --network-endpoint-type=serverless \
--cloud-run-service=today-cloud-run
# gcloud compute network-endpoint-groups delete today-serverless-neg --region=$REGION

gcloud compute network-endpoint-groups create tomorrow-serverless-neg --region=$REGION --network-endpoint-type=serverless \
--cloud-run-service=tomorrow-cloud-run
# gcloud compute network-endpoint-groups delete tomorrow-serverless-neg --region=$REGION

gcloud beta compute backend-services create today-service-backend --load-balancing-scheme=EXTERNAL_MANAGED --global
# gcloud beta compute backend-services delete today-service-backend --global
gcloud beta compute backend-services add-backend today-service-backend \
--network-endpoint-group=today-serverless-neg --network-endpoint-group-region=$REGION --global

gcloud beta compute backend-services create tomorrow-service-backend --load-balancing-scheme=EXTERNAL_MANAGED \
--global
# gcloud beta compute backend-services delete tomorrow-service-backend --global
gcloud beta compute backend-services add-backend tomorrow-service-backend \
--network-endpoint-group=tomorrow-serverless-neg --network-endpoint-group-region=$REGION --global
    
gcloud beta compute url-maps create cloud-native-map --default-service=today-service-backend --region=$REGION
OR, 
gcloud beta compute url-maps import cloud-native-map  --source=./LoadBalancer/url-map-global.yaml --global 
# gcloud beta compute url-maps delete cloud-native-map --global

gcloud beta compute target-http-proxies create cloud-lb-http-proxy --url-map=cloud-native-map --global
# gcloud beta compute target-http-proxies delete cloud-lb-http-proxy --global

gcloud beta compute target-https-proxies create cloud-lb-https-proxy --ssl-certificates=cloud-lb-cert --url-map=cloud-native-map \
--global
# gcloud beta compute target-https-proxies delete cloud-lb-https-proxy --global

gcloud beta compute forwarding-rules create cloud-lb-forwarding-rule \
--load-balancing-scheme=EXTERNAL_MANAGED --network-tier=PREMIUM \
--address=cloud-lb-address --target-http-proxy=cloud-lb-http-proxy \
--ports=80 --global

gcloud beta compute forwarding-rules create cloud-lb-forwarding-rule \
--load-balancing-scheme=EXTERNAL_MANAGED --network-tier=PREMIUM \
--address=cloud-lb-address --target-https-proxy=cloud-lb-https-proxy \
--ports=443 --global

# gcloud beta compute forwarding-rules delete cloud-lb-forwarding-rule --global

gcloud compute health-checks create https cloud-lb-health-check --check-interval=10s --timeout=10s --healthy-threshold=2 \
--unhealthy-threshold=3 --port 443 --global
# gcloud compute health-checks delete https cloud-lb-health-check

curl -k -H "Authorization: Bearer $(gcloud auth print-identity-token)" https://crun.wkshpdev.com/cr

Internal LB
==============================================================================================================================
gcloud compute networks create cloud-native-vpc --subnet-mode=custom
gcloud compute firewall-rules create allow-all-rule --network cloud-native-vpc --allow tcp,udp,icmp --source-ranges=0.0.0.0/0

gcloud compute networks subnets create cloud-lb-subnet --network=cloud-native-vpc --range=11.0.0.0/24
OR,
gcloud compute networks subnets create cloud-lb-subnet --network=cloud-native-vpc --range=11.0.0.0/24
# gcloud compute networks subnets delete cloud-lb-subnet

gcloud compute instances create cloud-lb-vm --network=cloud-native-vpc --subnet=cloud-lb-subnet --zone=$ZONE
# gcloud compute instances delete cloud-lb-vm --zone=$ZONE

gcloud compute networks subnets create proxy-only-subnet --purpose=REGIONAL_MANAGED_PROXY --role=ACTIVE \
--network=cloud-native-vpc --range=11.0.1.0/24
# gcloud compute networks subnets delete proxy-only-subnet

gcloud compute networks subnets create cloud-psc-subnet --network=cloud-native-vpc --region=$REGION \
--range=11.0.2.0/24 --purpose=PRIVATE_SERVICE_CONNECT
# gcloud compute networks subnets delete cloud-psc-subnet

gcloud compute addresses create cloud-lb-address --subnet=cloud-lb-subnet --region=$REGION
gcloud compute addresses describe cloud-lb-address --format="get(address)" --region=$REGION
# gcloud compute addresses delete cloud-lb-address --region=$REGION

gcloud compute network-endpoint-groups create today-serverless-neg --region=$REGION --network-endpoint-type=serverless \
--cloud-run-service=today-cloud-run
# gcloud compute network-endpoint-groups delete today-serverless-neg --region=$REGION

gcloud compute network-endpoint-groups create tomorrow-serverless-neg --region=$REGION --network-endpoint-type=serverless \
--cloud-run-service=tomorrow-cloud-run
# gcloud compute network-endpoint-groups delete tomorrow-serverless-neg --region=$REGION

gcloud beta compute backend-services create today-service-backend --load-balancing-scheme=INTERNAL_MANAGED --protocol=HTTPS \
--region=$REGION
# gcloud beta compute backend-services delete today-service-backend --region=$REGION
gcloud beta compute backend-services add-backend today-service-backend --region=$REGION \
--network-endpoint-group=today-serverless-neg --network-endpoint-group-region=$REGION

gcloud beta compute backend-services create tomorrow-service-backend --load-balancing-scheme=INTERNAL_MANAGED --protocol=HTTPS \
--region=$REGION
# gcloud beta compute backend-services delete tomorrow-service-backend --region=$REGION
gcloud beta compute backend-services add-backend tomorrow-service-backend --region=$REGION \
--network-endpoint-group=tomorrow-serverless-neg --network-endpoint-group-region=$REGION
    
gcloud beta compute url-maps create cloud-native-map --default-service=today-service-backend --region=$REGION
OR, 
gcloud beta compute url-maps import cloud-native-map  --source=./LoadBalancer/url-map.yaml --region=$REGION
# gcloud beta compute url-maps delete cloud-native-map --region=$REGION

## Self-signed certificate
===========================
openssl genrsa -out cloud-native.key 2048
openssl req -new -key cloud-native.key -out cloud-native.csr -config ossl-conf.txt
openssl x509 -req -signkey cloud-native.key -in cloud-native.csr -out cloud-native.pem -extfile ossl-conf.txt -extensions extension_requirements \
-days 360
gcloud compute ssl-certificates create cloud-internal-lb-cert --certificate=./Misc/Certs/internalnative.com/cloud-native.pem \
--private-key=./Misc/Certs/internalnative.com/cloud-native.key --region=$REGION
# gcloud compute ssl-certificates delete cloud-internal-lb-cert --region=$REGION
===========================

gcloud beta compute target-https-proxies create cloud-lb-https-proxy --ssl-certificates=cloud-internal-lb-cert \
--url-map=cloud-native-map --region=$REGION
# gcloud beta compute target-https-proxies delete cloud-lb-https-proxy --region=$REGION

gcloud beta compute forwarding-rules create cloud-lb-forwarding-rule \
--load-balancing-scheme=INTERNAL_MANAGED --network-tier=PREMIUM --network=cloud-native-vpc --subnet=cloud-lb-subnet \
--address=cloud-lb-address --target-https-proxy=cloud-lb-https-proxy --target-https-proxy-region=$REGION \
--region=$REGION --ports=443
# gcloud beta compute forwarding-rules delete cloud-lb-forwarding-rule --region=$REGION

gcloud compute instances create vm-client --image-family=debian-10 --image-project=debian-cloud --tags=allow-ssh \
--network=cloud-native-vpc --subnet=cloud-lb-subnet --zone=$ZONE
# gcloud compute instances delete vm-client --zone=$ZONE

gcloud compute ssh --zone $ZONE vm-client --project cloud-native-workshop

## Private Cloud DNS Zone
==========================
gcloud dns managed-zones create cloud-native-zone --dns-name internal.native.com. --visibility=private --networks=cloud-native-vpc \
--description="Private Zone"
# gcloud dns managed-zones delete cloud-native-zone

gcloud dns record-sets create crun.internal.native.com. \
--rrdatas=$(gcloud compute addresses describe cloud-lb-address --format="get(address)") --type=A --zone=cloud-native-zone
# gcloud dns record-sets delete crun.internal.native.com --type=A --zone=cloud-native-zone

curl -H "Authorization: Bearer $(gcloud auth print-identity-token)" http://crun.internal.native.com/cr
curl -k -H "Authorization: Bearer $(gcloud auth print-identity-token)" https://crun.internal.native.com/cr

## Service-attachment
============================================
gcloud beta compute service-attachments create cloud-run-attachment --region=$REGION \
--producer-forwarding-rule=cloud-lb-forwarding-rule --connection-preference=ACCEPT_AUTOMATIC \
--nat-subnets=cloud-psc-subnet
# gcloud beta compute service-attachments delete cloud-run-attachment

## Private Endpoint to Service-attachment
============================================

gcloud compute networks create cloud-psc-test-vpc --subnet-mode=custom
# gcloud compute networks delete cloud-psc-test-vpc

gcloud compute firewall-rules create allow-psc-test-all-rule --network cloud-psc-test-vpc --allow tcp,udp,icmp --source-ranges=0.0.0.0/0
# gcloud compute firewall-rules delete allow-psc-test-all-rule

gcloud compute networks subnets create cloud-psc-test-subnet --network=cloud-psc-test-vpc --region=$REGION \
--range=12.0.0.0/24
# gcloud compute networks subnets delete cloud-psc-test-subnet

gcloud compute addresses create psc-ip-endpoint --region=$REGION --subnet=cloud-psc-test-subnet
# gcloud compute addresses delete psc-ip-endpoint

gcloud compute forwarding-rules create fr-psc-endpoint --region=$REGION --network cloud-psc-test-vpc \
--address psc-ip-endpoint \
--target-service-attachment $(gcloud beta compute service-attachments describe cloud-run-attachment --format="get(selfLink)")
# gcloud compute forwarding-rules delete fr-psc-endpoint

gcloud compute instances create vm-psc-client --image-family=debian-10 --image-project=debian-cloud --tags=allow-ssh \
--network=cloud-psc-test-vpc --subnet=cloud-psc-test-subnet --zone=$ZONE
# gcloud compute instances delete vm-psc-client --zone=$ZONE

gcloud compute ssh --zone $ZONE vm-psc-client --project cloud-native-workshop

curl -H "Authorization: Bearer $(gcloud auth print-identity-token)" http://12.0.0.2/cr

## Global Https LB to Service-attachment
============================================
gcloud compute addresses create cloud-glb-address --ip-version=IPV4 --global
gcloud compute addresses describe cloud-glb-address --format="get(address)" --global
# gcloud compute addresses delete cloud-glb-address --global

gcloud beta compute network-endpoint-groups create cloud-glb-neg \
  --network-endpoint-type=private-service-connect \
  --psc-target-service=$(gcloud beta compute service-attachments describe cloud-run-attachment --region=$REGION \
  --format="get(selfLink)") --region=$REGION
# gcloud beta compute network-endpoint-groups delete cloud-glb-neg --region=$REGION

gcloud beta compute backend-services create cloud-glb-backend --load-balancing-scheme=EXTERNAL_MANAGED --protocol=HTTPS --global
# gcloud beta compute backend-services delete cloud-glb-backend --global

gcloud beta compute backend-services add-backend cloud-glb-backend \
  --network-endpoint-group=cloud-glb-neg --network-endpoint-group-region=$REGION --global

gcloud beta compute url-maps create cloud-glb-map --default-service=cloud-glb-backend --global
gcloud beta compute url-maps describe cloud-glb-map --format=yaml
# gcloud beta compute url-maps delete cloud-glb-map --global

gcloud beta compute target-https-proxies create cloud-glb-https-proxy --url-map=cloud-glb-map --ssl-certificates=cloud-lb-cert
# gcloud beta compute target-https-proxies delete cloud-glb-https-proxy --global

gcloud beta compute forwarding-rules create fr-glb-endpoint \
  --load-balancing-scheme=EXTERNAL_MANAGED \
  --network-tier=PREMIUM \
  --address=cloud-glb-address \
  --target-https-proxy=cloud-glb-https-proxy \
  --ports=443 --global
# gcloud beta compute forwarding-rules delete fr-glb-endpoint --global

curl -k -H "Authorization: Bearer $(gcloud auth print-identity-token)" https://cglbrun.wkshpdev.com/cr

Cloud Function
==========================================================================================

gcloud iam service-accounts add-iam-policy-binding cloud-native-workshop-sa@cloud-native-workshop.iam.gserviceaccount.com --member=user:datta.monojit@gmail.com --role=roles/iam.serviceAccountTokenCreator
# gcloud iam service-accounts remove-iam-policy-binding cloud-native-workshop-sa@cloud-native-workshop.iam.gserviceaccount.com --member=user:datta.monojit@gmail.com --role=roles/iam.serviceAccountTokenCreator

gcloud auth print-identity-token
gcloud auth print-identity-token --impersonate-service-account=cloud-native-workshop-sa@cloud-native-workshop.iam.gserviceaccount.com --audiences="https://$REGION-cloud-native-workshop.cloudfunctions.net/cloud-function-hello"

curl "http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/identity?audience=https://$REGION-cloud-native-workshop.cloudfunctions.net/cloud-function-hello" -H "Metadata-Flavor: Google"


Workflows
==========================================================================================



PubSub
==========================================================================================

gcloud pubsub topics publish cloud-native-topic --message="pubsub message1"
    

Redis
==========================================================================================
brew install redis

Artifact Registry
==========================================================================================
gcloud artifacts repositories create cloud-native-repo --location=$REGION --repository-format=docker
gcloud artifacts repositories list

gcloud auth configure-docker $REGION-docker.pkg.dev
docker pull us-docker.pkg.dev/google-samples/containers/gke/hello-app:1.0
docker tag us-docker.pkg.dev/google-samples/containers/gke/hello-app:1.0 $REGION-docker.pkg.dev/cloud-native-workshop/cloud-native-repo/hello-app:v1.0
docker push $REGION-docker.pkg.dev/cloud-native-workshop/cloud-native-repo/hello-app:v1.0
gcloud auth print-access-token | docker login -u oauth2accesstoken --password-stdin https://$REGION-docker.pkg.dev

gcloud artifacts docker images list $REGION-docker.pkg.dev/cloud-native-workshop/cloud-native-repo
gcloud artifacts docker images delete $REGION-docker.pkg.dev/cloud-native-workshop/cloud-native-repo/hello-app

docker build --platform=linux/amd64 -t $REGION-docker.pkg.dev/cloud-native-workshop/cloud-native-repo/today-cloud-run:v1.0 .
docker run --name today-cloud-run -d -p 8080:8080 $REGION-docker.pkg.dev/cloud-native-workshop/cloud-native-repo/today-cloud-run:v1.0
docker push $REGION-docker.pkg.dev/cloud-native-workshop/cloud-native-repo/today-cloud-run:v1.0

gcloud artifacts docker images list $REGION-docker.pkg.dev/cloud-native-workshop/cloud-native-repo
# gcloud artifacts docker images delete $REGION-docker.pkg.dev/cloud-native-workshop/cloud-native-repo/today-cloud-run

docker build --platform=linux/amd64 -t $REGION-docker.pkg.dev/cloud-native-workshop/cloud-native-repo/tomorrow-cloud-run:v1.0 .
docker run --name today-cloud-run -d -p 8080:8080 $REGION-docker.pkg.dev/cloud-native-workshop/cloud-native-repo/tomorrow-cloud-run:v1.0
docker push $REGION-docker.pkg.dev/cloud-native-workshop/cloud-native-repo/tomorrow-cloud-run:v1.0

gcloud artifacts docker images list $REGION-docker.pkg.dev/cloud-native-workshop/cloud-native-repo
# gcloud artifacts docker images delete $REGION-docker.pkg.dev/cloud-native-workshop/cloud-native-repo/tomorrow-cloud-run

App Engines
==========================================================================================
gcloud app create --project=cloud-native-workshop --region=$REGION
git clone https://github.com/GoogleCloudPlatform/nodejs-docs-samples
gcloud app deploy

git clone https://github.com/GoogleCloudPlatform/dotnet-docs-samples
dotnet restore
dotnet publish -c Release
gcloud app deploy .\bin\Debug\net6.0\publish\app.yaml

gcloud app deploy --service-account=cloud-native-workshop-sa@cloud-native-workshop.iam.gserviceaccount.com --version=v10

Cloud Run
==========================================================================================

gcloud run deploy today-cloud-run --source=. --cpu=1 --memory=500Mi --min-instances=1 --region=$REGION \
--service-account=cloud-native-workshop-sa@cloud-native-workshop.iam.gserviceaccount.com --ingress=internal-and-cloud-load-balancing \
--revision-suffix=v10 --allow-unauthenticated

gcloud run deploy today-cloud-run --image="$REGION-docker.pkg.dev/cloud-native-workshop/cloud-native-repo/today-cloud-run:v1.0" \
--cpu=1 --memory=500Mi --min-instances=1 --region=$REGION --port=7071 \
--service-account=cloud-native-workshop-sa@cloud-native-workshop.iam.gserviceaccount.com --ingress=internal-and-cloud-load-balancing \
--revision-suffix=v10

# gcloud run services delete today-cloud-run --region=$REGION
curl -H "Authorization: Bearer $(gcloud auth print-identity-token)" https://today-cloud-run-pqkdv6pa6q-as.a.run.app

gcloud run deploy tomorrow-cloud-run --source=. --cpu=1 --memory=500Mi --min-instances=1 --region=$REGION \
--service-account=cloud-native-workshop-sa@cloud-native-workshop.iam.gserviceaccount.com --ingress=internal-and-cloud-load-balancing \
--revision-suffix=v10 --allow-unauthenticated
# gcloud run services delete tomorrow-cloud-run --region=$REGION

gcloud run services add-iam-policy-binding hello-cloud-run --region=$REGION \
  --member="serviceAccount:cloud-native-workshop-sa@cloud-native-workshop.iam.gserviceaccount.com" --role="roles/run.invoker"

gcloud run services delete hello-cloud-run --region=$REGION

Cloud Tasks
==========================================================================================

git clone https://github.com/googleapis/nodejs-tasks.git
cd nodejs-tasks/samples

git clone https://github.com/GoogleCloudPlatform/dotnet-docs-samples
cd dotnet-docs-samples/cloudtasks/api/TasksSample/

gcloud tasks queues create cloud-native-queue
gcloud tasks queues describe cloud-native-queue

GKE (Standard)
====================
ZONE2="$REGION-c"

gcloud compute networks create gke-cluster-vpc --subnet-mode=custom
gcloud compute firewall-rules create gke-allow-all-rule --network gke-cluster-vpc --allow tcp,udp,icmp --source-ranges=0.0.0.0/0

gcloud compute networks subnets create $CLUSTER_SUBNET_NAME --network=gke-cluster-vpc --range=12.0.0.0/22
gcloud compute networks subnets update $CLUSTER_SUBNET_NAME --add-secondary-ranges=pods-range=12.1.0.0/16,services-range=12.2.0.0/16
# gcloud compute networks subnets delete $CLUSTER_SUBNET_NAME 

gcloud compute networks subnets create $PROXY_SUBNET_NAME --purpose=REGIONAL_MANAGED_PROXY --role=ACTIVE \
--network=gke-cluster-vpc --range=12.0.4.0/24
# gcloud compute networks subnets delete $PROXY_SUBNET_NAME

gcloud compute networks subnets create $PSC_SUBNET_NAME --purpose=PRIVATE_SERVICE_CONNECT --role=ACTIVE \
--network=gke-cluster-vpc --range=12.0.5.0/24
# gcloud compute networks subnets delete $PSC_SUBNET_NAME

gcloud compute networks subnets create gke-psc-test-subnet --network=gke-cluster-vpc --region=$REGION \
--range=12.0.6.0/24
# gcloud compute networks subnets delete gke-psc-test-subnet

gcloud components install gke-gcloud-auth-plugin
gke-gcloud-auth-plugin --version

gcloud container clusters create zonal-gke-cluster --release-channel=regular --network=gke-cluster-vpc \
--subnetwork=$CLUSTER_SUBNET_NAME \
--zone=$ZONE --num-nodes=1 --node-locations=$ZONE,$ZONE2 --enable-ip-alias \
--cluster-ipv4-cidr=10.0.0.0/16 --services-ipv4-cidr=10.1.0.0/16
# gcloud container clusters delete zonal-gke-cluster

gcloud container clusters get-credentials  zonal-gke-cluster --zone=$ZONE

## Self-signed certificate
===========================
# mkdir internalgke.com && cd internalgke.com

openssl genrsa -out internal-gke.key 2048
openssl req -new -key internal-gke.key -out internal-gke.csr -config gke-ossl-conf.txt
openssl x509 -req -signkey internal-gke.key -in internal-gke.csr -out internal-gke.pem -extfile gke-ossl-conf.txt \
-extensions extension_requirements -days 360

gcloud compute ssl-certificates create gke-ingress-cert --certificate=./Misc/Certs/internalgke.com/internal-gke.pem \
--private-key=./Misc/Certs/internalgke.com/internal-gke.key --region=$REGION
# gcloud compute ssl-certificates delete gke-ingress-cert --region=$REGION
===========================
Or, Secret
===========================
k create secret tls gke-ingress-cert --cert="./Misc/Certs/internalgke.com/internal-gke.pem" \
--key="./Misc/Certs/internalgke.com/internal-gke.key"
===========================

git clone https://github.com/GoogleCloudPlatform/kubernetes-engine-samples
cd kubernetes-engine-samples/load-balancing

gcloud dns managed-zones create gke-internal-zone --dns-name internal.gke.com. --visibility=private \
--networks=gke-cluster-vpc --description="Private Zone"
# gcloud dns managed-zones delete gke-internal-zone

gcloud dns record-sets create ingress.internal.gke.com. \
--rrdatas=12.0.0.11 --type=A --zone=gke-internal-zone

gcloud dns record-sets update ingress.internal.gke.com. \
--rrdatas=12.0.0.13 --type=A --zone=gke-internal-zone --ttl=1800
# gcloud dns record-sets delete ingress.internal.native.com --type=A --zone=gke-internal-zone

gcloud compute instances create vm-psc-client --image-family=debian-10 --image-project=debian-cloud --tags=allow-ssh \
--network=gke-cluster-vpc --subnet=gke-psc-test-subnet --zone=$ZONE
# gcloud compute instances delete vm-psc-client --zone=$ZONE

gcloud compute ssh --zone $ZONE vm-psc-client --project cloud-native-workshop

curl -k https://ingress.internal.gke.com/

## GKE Service-attachment
============================================
gcloud beta compute service-attachments create gke-ingress-attachment --region=$REGION \
--producer-forwarding-rule=k8s2-fs-365qacpe-default-internal-ingress-x1ngf2g6 --connection-preference=ACCEPT_AUTOMATIC \
--nat-subnets=$PSC_SUBNET_NAME
# gcloud beta compute service-attachments delete gke-ingress-attachment

## Global Https LB to GKE Service-attachment
============================================
gcloud beta compute network-endpoint-groups create gke-glb-neg \
  --network-endpoint-type=private-service-connect \
  --psc-target-service=$(gcloud beta compute service-attachments describe gke-ingress-attachment --region=$REGION \
  --format="get(selfLink)") --region=$REGION
# gcloud beta compute network-endpoint-groups delete gke-glb-neg --region=$REGION

gcloud compute addresses create gke-glb-address --ip-version=IPV4 --global
gcloud compute addresses describe gke-glb-address --format="get(address)" --global
# gcloud compute addresses delete gke-glb-address --global

gcloud beta compute backend-services create gke-glb-backend --load-balancing-scheme=EXTERNAL_MANAGED --protocol=HTTPS --global
# gcloud beta compute backend-services delete gke-glb-backend --global

gcloud beta compute backend-services add-backend gke-glb-backend \
  --network-endpoint-group=gke-glb-neg --network-endpoint-group-region=$REGION --global

gcloud beta compute url-maps create gke-glb-map --default-service=gke-glb-backend --global
gcloud beta compute url-maps describe gke-glb-map --format=yaml
# gcloud beta compute url-maps delete gke-glb-map --global

gcloud beta compute target-https-proxies create gke-glb-https-proxy --url-map=gke-glb-map --ssl-certificates=cloud-lb-cert --global
# gcloud beta compute target-https-proxies delete gke-glb-https-proxy --global

gcloud beta compute forwarding-rules create gke-fr-glb-endpoint \
  --load-balancing-scheme=EXTERNAL_MANAGED \
  --network-tier=PREMIUM \
  --address=gke-glb-address \
  --target-https-proxy=gke-glb-https-proxy \
  --ports=443 --global
# gcloud beta compute forwarding-rules delete gke-fr-glb-endpoint --global

curl -k https://gkeapps.wkshpdev.com/


GKE (AutoPilot)
=================

gcloud container clusters create-auto my-autopilot-cluster --region $REGION
# gcloud container clusters delete my-autopilot-cluster --region $REGION
gcloud container clusters get-credentials my-autopilot-cluster --region $REGION

git clone https://github.com/GoogleCloudPlatform/microservices-demo.git

## Private AutoPilot Cluster
==============================
gcloud compute networks create gke-auto-cluster-vpc --subnet-mode=custom

gcloud compute networks subnets create gke-auto-cluster-subnet --network=gke-auto-cluster-vpc --range=13.0.0.0/22 \
--enable-private-ip-google-access

gcloud compute networks subnets create gke-jumper-subnet --network=gke-auto-cluster-vpc --range=13.0.4.0/24
# gcloud compute networks subnets delete gke-jumper-subnet

gcloud compute networks subnets create gke-auto-proxy-only-subnet --purpose=REGIONAL_MANAGED_PROXY --role=ACTIVE \
--network=gke-auto-cluster-vpc --range=13.0.5.0/24
# gcloud compute networks subnets delete gke-auto-proxy-only-subnet

gcloud compute networks subnets update gke-auto-cluster-subnet \
--add-secondary-ranges=pods-range=13.1.0.0/16,services-range=13.2.0.0/16
# gcloud compute networks subnets delete gke-auto-cluster-subnet

gcloud compute firewall-rules create gke-allow-ssh-rule --network=gke-auto-cluster-vpc --allow tcp:22 \
--source-ranges=0.0.0.0/0
# gcloud compute firewall-rules delete gke-allow-ssh-rule

gcloud compute firewall-rules create fw-allow-health-check \
    --network=gke-auto-cluster-vpc \
    --action=allow --direction=ingress --source-ranges=130.211.0.0/22,35.191.0.0/16 \
    --rules=tcp

gcloud compute firewall-rules create fw-allow-proxies \
  --network=gke-auto-cluster-vpc \
  --action=allow --direction=ingress --source-ranges=13.0.5.0/24 \
  --rules=tcp:80,tcp:443,tcp:8080

gcloud container clusters create-auto gke-auto-private-cluster \
    --region $REGION \
    --enable-master-authorized-networks \
    --network gke-auto-cluster-vpc \
    --subnetwork gke-auto-cluster-subnet --cluster-secondary-range-name pods-range --services-secondary-range-name services-range \
    --enable-private-nodes

# gcloud container clusters delete gke-auto-private-cluster --region=$REGION
gcloud container clusters get-credentials gke-auto-private-cluster --region $REGION

## Jumper VM
===============
gcloud compute instances create gke-jumper-client --image-family=debian-10 --image-project=debian-cloud --tags=allow-ssh \
--network=gke-auto-cluster-vpc --subnet=gke-jumper-subnet --zone=$ZONE
# gcloud compute instances delete gke-jumper-client --zone=$ZONE

gcloud container clusters update gke-auto-private-cluster --enable-master-authorized-networks \
--master-authorized-networks=35.187.232.75/32 --region=$REGION

gcloud compute ssh --zone $ZONE gke-jumper-client --project cloud-native-workshop

## Connect from Peering
================================================

gcloud compute networks create gke-peer-vpc --subnet-mode=custom
# gcloud compute networks delete gke-peer-vpc

gcloud compute networks subnets create gke-peer-subnet --network=gke-peer-vpc --range=14.0.0.0/24
# gcloud compute networks subnets delete gke-peer-subnet

gcloud compute networks peerings create peer12 --network=gke-peer-vpc --peer-network=gke-auto-cluster-vpc \
--import-subnet-routes-with-public-ip
# gcloud compute networks peerings delete peer12 --network=gke-peer-vpc

gcloud compute networks peerings create peer21 --network=gke-auto-cluster-vpc --peer-network=gke-peer-vpc \
--import-subnet-routes-with-public-ip
# gcloud compute networks peerings delete peer21 --network=gke-auto-cluster-vpc

gcloud compute instances create gke-jumper2-client --image-family=debian-10 --image-project=debian-cloud --tags=allow-ssh \
--network=gke-peer-vpc --subnet=gke-peer-subnet --zone=$ZONE
# gcloud compute instances delete gke-jumper2-client --zone=$ZONE

gcloud container clusters update gke-auto-private-cluster --enable-master-authorized-networks \
--master-authorized-networks=35.187.232.75/32,34.124.196.55/32 --region=$REGION

gcloud compute firewall-rules create gke-allow-peer-ssh-rule --network=gke-peer-vpc --allow tcp:22 \
--source-ranges=0.0.0.0/0
# gcloud compute firewall-rules delete gke-allow-peer-ssh-rule

gcloud compute ssh --zone $ZONE gke-jumper2-client --project cloud-native-workshop

================================================================================================

Apigee X (Old Approach)
==========================================================================================

AUTH="Authorization: Bearer $(gcloud auth print-access-token)"
PROJECT_ID="cloud-native-workshop"
RUNTIME_LOCATION="$REGION"
ANALYTICS_REGION="$REGION"

echo $AUTH
echo $PROJECT_ID
echo $RUNTIME_LOCATION
echo $ANALYTICS_REGION

gcloud compute networks subnets create gke-apigee-subnet --network=gke-auto-cluster-vpc --range=13.0.8.0/22
# gcloud compute networks subnets delete gke-apigee-subnet

gcloud compute networks subnets create gke-apigee-troublesdhoot-subnet --network=gke-auto-cluster-vpc --range=13.0.12.0/28
# gcloud compute networks subnets delete gke-apigee-troublesdhoot-subnet

gcloud services enable apigee.googleapis.com \
  servicenetworking.googleapis.com compute.googleapis.com \
  cloudkms.googleapis.com --project=$PROJECT_ID

RANGE_NAME=google-svcs
NETWORK_NAME=gke-auto-cluster-vpc

gcloud compute addresses create $RANGE_NAME \
  --global \
  --prefix-length=22 \
  --network=$NETWORK_NAME --purpose=VPC_PEERING --project=$PROJECT_ID
# gcloud compute addresses delete $RANGE_NAME --global

gcloud compute addresses create google-managed-services-support-1 \
  --global \
  --prefix-length=28 \
  --network=$NETWORK_NAME --purpose=VPC_PEERING --project=$PROJECT_ID
# gcloud compute addresses delete  google-managed-services-support-1 --global

gcloud services vpc-peerings connect \
  --service=servicenetworking.googleapis.com \
  --network=$NETWORK_NAME --ranges=$RANGE_NAME,google-managed-services-support-1 --project=$PROJECT_ID
# gcloud services vpc-peerings delete <peering> --network=$NETWORK_NAME

gcloud alpha apigee organizations provision \
  --runtime-location=$RUNTIME_LOCATION \
  --analytics-region=$ANALYTICS_REGION \
  --authorized-network=$NETWORK_NAME --project=$PROJECT_ID
# gcloud alpha apigee organizations delete <org>

gcloud services peered-dns-domains create gke-internal-dns --network=gke-auto-cluster-vpc --service="servicenetworking.googleapis.com" \
--dns-suffix=gkeauto.internal.gke.com

gcloud compute ssh --zone $ZONE gke-jumper-client --project cloud-native-workshop

sudo apt-get update -y
sudo apt-get install -y jq

export AUTH="Authorization: Bearer $(gcloud auth print-access-token)"
export PROJECT_ID=cloud-native-workshop
export ENV_GROUP_HOSTNAME=$(curl -H "$AUTH" https://apigee.googleapis.com/v1/organizations/$PROJECT_ID/envgroups -s | jq -r '.environmentGroups[0].hostnames[0]')
export INTERNAL_LOAD_BALANCER_IP=$(curl -H "$AUTH" https://apigee.googleapis.com/v1/organizations/$PROJECT_ID/instances -s | jq -r '.instances[0].host')

echo $AUTH
echo $PROJECT_ID
echo $ENV_GROUP_HOSTNAME
echo $INTERNAL_LOAD_BALANCER_IP

curl -i -k -H "Host: $ENV_GROUP_HOSTNAME" https://$INTERNAL_LOAD_BALANCER_IP/hello-world

==========================================================================================

Terraform
==========================================================================================
brew tap hashicorp/tap
brew install hashicorp/tap/terraform
brew update
brew upgrade hashicorp/tap/terraform

terraform init --backend-config=./backend.tfbackend
# terraform init --backend-config=./backend.tfbackend --reconfigure

terraform plan -out out.plan
terraform apply out.plan

terraform plan -destroy -out out.destroy.plan
terraform apply out.destroy.plan

AngularJS/Yarn
===============
npm install -g @angular/cli
sudo corepack enable

Let's Encrypt
===============
certbot certificates
certbot certonly -d *.kodemongers.com --dry-run --preferred-challenges=dns --manual
# certbot revoke --cert-name kodemongers.com
# certbot delete --cert-name kodemongers.com

ln -s /Users/monojitd/Workloads/Development/Documents/DNS-Certs/kodemongers.com \
/Users/monojitd/Workloads/Development/Projects/GithubProjects/Workshops/GCP-Workshop/Misc/Certs/


certbot certonly -d *.<dns-name>.com --dry-run --preferred-challenges=dns --manual
certbot certonly -d *.<dns-name>.com --preferred-challenges=dns --manual
# certbot revoke --cert-name <dns-name>.com
# certbot delete --cert-name <dns-name>.com

ln -s /Users/monojitd/Workloads/Development/Documents/DNS-Certs/<dns-name>.com \
/Users/monojitd/Workloads/Development/Projects/GithubProjects/Workshops/GCP-Workshop/Misc/Certs/

openssl pkcs12 -export -out cert.pfx -in cert.pem -inkey privkey.pem

openssl x509 -outform der -in cert.pem -out cert.crt
openssl x509 -inform der -in cert.crt -text